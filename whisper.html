<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Whisper: The Ultimate ASR Guide</title>
    <script src="redirect_if_needed.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700;800&display=swap" rel="stylesheet">
    <meta name="description" content="A complete guide to OpenAI's Whisper model. Understand its technology, capabilities, applications, and its impact on automatic speech recognition (ASR).">
    <meta name="keywords" content="OpenAI, Whisper, ASR, Automatic Speech Recognition, AI Transcription, Speech-to-Text, AI, Artificial Intelligence, Machine Learning">
    <meta name="author" content="AI Tools Guide">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #121212; /* Dark Charcoal */
            color: #e0e0e0; /* Light Gray */
        }
        .section-heading {
            border-image: linear-gradient(to right, #00f0b5, #9f7aea) 1;
            border-bottom: 4px solid;
            padding-bottom: 0.5rem;
            margin-bottom: 1.5rem;
            display: inline-block;
            color: #ffffff; /* White */
        }
        .card {
            background: rgba(28, 28, 28, 0.85); /* Dark Gray Transparent */
            backdrop-filter: blur(16px);
            -webkit-backdrop-filter: blur(16px);
            border-radius: 1.25rem;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.6);
            padding: 2rem;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            border: 1px solid #333333; /* Medium Gray */
        }
        .card:hover {
            box-shadow: 0 0 40px rgba(0, 240, 181, 0.2);
            transform: translateY(-12px) scale(1.02);
            border-color: #00f0b5; /* Vibrant Teal */
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 550px;
            margin: auto;
            height: 320px;
            max-height: 450px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 380px;
            }
        }
        .flowchart-step {
            border: 3px solid #00f0b5; /* Vibrant Teal */
            color: #00f0b5;
            background: #1c1c1c; /* Darker Gray */
            transition: all 0.3s ease-in-out;
            cursor: pointer;
            box-shadow: 0 0 15px rgba(0, 240, 181, 0.2);
            text-shadow: 0 0 5px rgba(0, 240, 181, 0.5);
        }
        .flowchart-step:hover {
            background-color: #00f0b5;
            color: #121212;
            transform: scale(1.08);
            box-shadow: 0 0 25px rgba(0, 240, 181, 0.5);
        }
        .flowchart-arrow {
            color: #9f7aea; /* Light Purple */
            text-shadow: 0 0 10px rgba(159, 122, 234, 0.5);
        }
        .subject-category-heading {
            color: #ffffff;
            font-weight: 700;
            margin-bottom: 1rem;
            font-size: 1.3rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #9f7aea;
        }
        .subject-item {
            display: flex;
            align-items: center;
            margin-bottom: 0.75rem;
            padding: 0.75rem;
            border-radius: 0.75rem;
            transition: background-color 0.2s;
        }
        .subject-item:hover {
            background-color: rgba(159, 122, 234, 0.1);
        }
        .subject-item .icon {
            color: #9f7aea;
            margin-right: 1rem;
            font-size: 1.5rem;
        }
        .timeline-step {
            position: relative;
            padding-left: 2.5rem;
            padding-bottom: 2.5rem;
            border-left: 4px solid #00f0b5;
        }
        .timeline-step:last-child {
            padding-bottom: 0;
        }
        .timeline-dot {
            position: absolute;
            left: -0.9375rem;
            top: 0;
            width: 1.75rem;
            height: 1.75rem;
            border-radius: 50%;
            background-color: #121212;
            border: 4px solid #00f0b5;
            box-shadow: 0 0 15px rgba(0, 240, 181, 0.7);
        }
        .modal-overlay {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background-color: rgba(18, 18, 18, 0.85);
            backdrop-filter: blur(8px);
            -webkit-backdrop-filter: blur(8px);
            display: flex;
            align-items: center; justify-content: center;
            z-index: 1000;
            opacity: 0; visibility: hidden;
            transition: opacity 0.3s ease, visibility 0.3s ease;
            padding: 1rem;
        }
        .modal-overlay.active {
            opacity: 1; visibility: visible;
        }
        .modal-content {
            background-color: #1c1c1c;
            border-radius: 1rem;
            padding: 2.5rem;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.5);
            max-width: 800px;
            width: 100%;
            position: relative;
            transform: translateY(20px) scale(0.98);
            opacity: 0;
            transition: transform 0.4s ease, opacity 0.4s ease;
            max-height: 90vh;
            overflow-y: auto;
            border: 1px solid #333333;
        }
        .modal-overlay.active .modal-content {
            transform: translateY(0) scale(1);
            opacity: 1;
        }
        .modal-close-button {
            position: absolute; top: 1rem; right: 1rem;
            background: none; border: none; font-size: 2.5rem;
            cursor: pointer; color: #9ca3af; line-height: 1;
            transition: color 0.2s, transform 0.2s;
        }
        .modal-close-button:hover { color: #f87171; transform: rotate(90deg); }
        .modal-action-button {
            background: linear-gradient(45deg, #00f0b5, #00d4a1);
            color: #121212;
            padding: 0.85rem 1.75rem;
            border-radius: 0.75rem;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.3s ease;
            border: none;
            box-shadow: 0 5px 15px rgba(0, 240, 181, 0.3);
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        .modal-action-button:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(0, 240, 181, 0.4);
        }
        .lang-btn {
            padding: 0.6rem 2rem;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.3s;
            border: 2px solid #00f0b5;
            color: #00f0b5;
            background-color: transparent;
        }
        .lang-btn:first-child { border-top-left-radius: 0.75rem; border-bottom-left-radius: 0.75rem; }
        .lang-btn:last-child { border-top-right-radius: 0.75rem; border-bottom-right-radius: 0.75rem; }
        .lang-btn.active, .lang-btn:hover {
            background-color: #00f0b5;
            color: #121212;
            box-shadow: 0 0 15px #00f0b5;
        }
        .notes-btn, .lectures-btn {
            padding: 0.35rem 1rem;
            border-radius: 0.5rem;
            font-size: 0.875rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s ease-in-out;
            border: 1px solid transparent;
            text-transform: uppercase;
        }
        .notes-btn {
            background: linear-gradient(45deg, #9f7aea, #8b5cf6);
            color: #ffffff;
        }
        .notes-btn:hover {
            filter: brightness(1.2);
        }
        .lectures-btn {
            background-color: #2a2a2a; 
            color: #e0e0e0; 
            border-color: #333333; 
        }
        .lectures-btn:hover {
            background-color: #333333;
            color: #ffffff;
        }
    </style>
</head>
<body class="leading-relaxed">

    <div class="container mx-auto p-4 sm:p-6 md:p-12">

        <header class="text-center mb-10">
            <h1 id="header-title" class="text-4xl md:text-5xl font-extrabold text-[#ffffff] mb-4 tracking-tight">üéôÔ∏è OpenAI Whisper: The Ultimate Guide üéôÔ∏è</h1>
            <p id="header-subtitle" class="text-xl md:text-2xl font-semibold bg-clip-text text-transparent bg-gradient-to-r from-teal-300 to-purple-400">Unlocking the Power of Automated Speech Recognition</p>
        </header>

        <div class="text-center mb-12">
            <div class="inline-flex rounded-md shadow-sm" role="group">
                <button type="button" class="lang-btn active" data-lang="en">English</button>
                <button type="button" class="lang-btn" data-lang="hi">‡§π‡§ø‡§Ç‡§¶‡•Ä</button>
            </div>
        </div>

        <main class="grid grid-cols-1 gap-12">

            <!-- Section 1: What is Whisper? -->
            <section class="card !p-0 overflow-hidden bg-gradient-to-br from-[#1c1c1c] via-[#121212] to-[#121212]">
                <div class="p-8">
                    <h2 id="sec1-title" class="text-3xl font-bold section-heading">1. What is OpenAI Whisper? üí°</h2>
                    <p id="sec1-p1" class="text-lg mb-6">OpenAI Whisper is a state-of-the-art Automatic Speech Recognition (ASR) model. Unlike general-purpose models like GPT, Whisper is specifically designed for one primary task: converting spoken language into written text with remarkable accuracy. Trained on a vast and diverse dataset of audio, it achieves human-level robustness and accuracy across a wide range of languages, accents, and noisy environments, making it a powerful tool for transcription and translation.</p>
                </div>
                <div id="postCardsContainer" class="px-8 pb-8 pt-2 grid grid-cols-1 md:grid-cols-3 gap-8 bg-transparent">
                    <!-- Cards will be dynamically inserted here by JavaScript -->
                </div>
            </section>

            <!-- Section 2: How It Works -->
            <section class="card">
                <h2 id="sec2-title" class="text-3xl font-bold section-heading text-center w-full">2. How Whisper Works üéØ</h2>
                <p id="sec2-p1" class="text-lg text-center mb-10 max-w-3xl mx-auto">Whisper uses a sophisticated end-to-end Transformer architecture to process audio and predict the corresponding text sequence.</p>
                <div class="flex flex-col md:flex-row items-center justify-center space-y-8 md:space-y-0 md:space-x-8 lg:space-x-16">
                    <div class="text-center flex flex-col items-center">
                        <div class="w-40 h-40 flex items-center justify-center rounded-full flowchart-step font-bold text-lg p-3 text-center leading-tight" data-modal-target="prelimsMainModal"><span id="sec2-step1-title">Input</span><br><span id="sec2-step1-name">Audio File</span></div>
                        <p id="sec2-step1-desc" class="mt-4 font-semibold text-gray-400">Audio is split into 30-second chunks</p>
                    </div>
                    <div class="text-5xl font-light flowchart-arrow transform md:rotate-0 rotate-90">‚Üí</div>
                    <div class="text-center flex flex-col items-center">
                        <div class="w-40 h-40 flex items-center justify-center rounded-full flowchart-step font-bold text-lg p-3 text-center leading-tight" data-modal-target="mainsMainModal"><span id="sec2-step2-title">Whisper Model</span><br><span id="sec2-step2-name">Encoder-Decoder</span></div>
                        <p id="sec2-step2-desc" class="mt-4 font-semibold text-gray-400">Audio is processed and text is predicted</p>
                    </div>
                    <div class="text-5xl font-light flowchart-arrow transform md:rotate-0 rotate-90">‚Üí</div>
                    <div class="text-center flex flex-col items-center">
                        <div class="w-40 h-40 flex items-center justify-center rounded-full flowchart-step font-bold text-lg p-3 text-center leading-tight" data-modal-target="interviewModal"><span id="sec2-step3-title">Output</span><br><span id="sec2-step3-name">Text Transcript</span></div>
                        <p id="sec2-step3-desc" class="mt-4 font-semibold text-gray-400">The final transcribed text is generated</p>
                    </div>
                </div>
            </section>

            <!-- Section 3: Access & Availability -->
            <section class="card">
                <h2 id="sec3-title" class="text-3xl font-bold section-heading">3. Who Can Use It? ‚úÖ</h2>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 items-start">
                    <div>
                        <p id="sec3-p1" class="text-lg mb-6">Whisper is designed to be accessible to a broad audience, from individual developers to large corporations.</p>
                        <ul class="space-y-5 text-base">
                            <li class="flex items-start"><span class="text-3xl text-[#00f0b5] mr-4">üßë‚Äçüíª</span><div><strong id="sec3-age-title" class="text-white text-lg">Developers & Researchers:</strong> <span id="sec3-age-desc">The primary users, integrating Whisper into applications for transcription, translation, and voice-enabled features.</span></div></li>
                            <li class="flex items-start"><span class="text-3xl text-[#00f0b5] mr-4">üé¨</span><div><strong id="sec3-edu-title" class="text-white text-lg">Content Creators & Media:</strong> <span id="sec3-edu-desc">Used for creating accurate subtitles for videos, transcribing podcasts, and generating text from interviews.</span></div></li>
                        </ul>
                    </div>
                    <div>
                        <h3 id="sec3-attempts-title" class="text-2xl font-bold text-white mb-4 border-b border-[#9f7aea] pb-2">Primary Platforms üìä</h3>
                         <ul id="sec3-agerelax-list" class="list-disc list-inside space-y-3 text-base">
                             <li><strong>OpenAI API:</strong> The easiest way to use the latest, most optimized Whisper model on a pay-as-you-go basis.</li>
                             <li><strong>Open Source:</strong> OpenAI has open-sourced the Whisper models and code, allowing anyone to run them on their own hardware.</li>
                             <li><strong>Third-Party Services:</strong> Numerous applications and services have integrated Whisper to offer transcription features.</li>
                        </ul>
                    </div>
                </div>
            </section>
            
            <!-- Section 4: Core Capabilities -->
            <section class="card bg-black/20">
                <h2 id="sec4-title" class="text-3xl font-bold section-heading text-center w-full">4. Core Capabilities üìö</h2>
                <p id="sec4-p1" class="text-lg text-center mb-10 max-w-4xl mx-auto">Whisper's architecture allows it to perform multiple complex speech-processing tasks simultaneously.</p>
                 <div id="syllabus-grid" class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8">
                    <div class="bg-[#1c1c1c]/80 backdrop-blur-sm p-6 rounded-xl shadow-lg border border-slate-700 flex flex-col transition duration-300 hover:shadow-2xl hover:border-teal-400 hover:-translate-y-1">
                        <h3 id="gs1-title" class="subject-category-heading">Transcription</h3>
                        <p class="text-sm">Highly accurate speech-to-text in multiple languages.</p>
                    </div>
                     <div class="bg-[#1c1c1c]/80 backdrop-blur-sm p-6 rounded-xl shadow-lg border border-slate-700 flex flex-col transition duration-300 hover:shadow-2xl hover:border-teal-400 hover:-translate-y-1">
                        <h3 id="gs2-title" class="subject-category-heading">Translation</h3>
                         <p class="text-sm">Translating speech from any supported language directly into English text.</p>
                    </div>
                    <div class="bg-[#1c1c1c]/80 backdrop-blur-sm p-6 rounded-xl shadow-lg border border-slate-700 flex flex-col transition duration-300 hover:shadow-2xl hover:border-teal-400 hover:-translate-y-1">
                        <h3 id="gs3-title" class="subject-category-heading">Language ID</h3>
                         <p class="text-sm">Automatically identifying the language being spoken in the audio.</p>
                    </div>
                    <div class="bg-[#1c1c1c]/80 backdrop-blur-sm p-6 rounded-xl shadow-lg border border-slate-700 flex flex-col transition duration-300 hover:shadow-2xl hover:border-teal-400 hover:-translate-y-1">
                        <h3 id="gs4-title" class="subject-category-heading">Timestamping</h3>
                         <p class="text-sm">Providing word-level or segment-level timestamps for easy navigation and subtitling.</p>
                    </div>
                </div>
            </section>

            <!-- Section 5: Training & Data -->
            <section class="card">
                <h2 id="sec5-title" class="text-3xl font-bold section-heading">5. How was Whisper Trained? üèõÔ∏è</h2>
                <p id="sec5-p1" class="text-lg text-center mb-8 max-w-3xl mx-auto">Whisper's robustness comes from its unique training on a massive and incredibly diverse dataset, which distinguishes it from traditional ASR systems.</p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 text-base">
                    <div class="p-6 bg-[#1c1c1c] rounded-xl border-2 border-[#00f0b5]">
                        <h3 id="sec5-hindi-title" class="font-bold text-xl text-white mb-2">1. The Dataset</h3>
                        <p id="sec5-hindi-p1" class="text-sm mb-2">A large and diverse supervised dataset.</p>
                        <ul id="sec5-hindi-list" class="list-disc list-inside space-y-1 mt-2 text-sm">
                            <li>Trained on **680,000 hours** of multilingual and multitask supervised data collected from the web.</li>
                            <li>This diversity improves robustness to different accents, background noise, and technical language.</li>
                            <li>About one-third of the audio data is non-English, enabling powerful multilingual capabilities.</li>
                        </ul>
                    </div>
                    <div class="p-6 bg-[#1c1c1c] rounded-xl border-2 border-[#9f7aea]">
                        <h3 id="sec5-essay-title" class="font-bold text-xl text-white mb-2">2. The Training Process</h3>
                        <p id="sec5-essay-p1" class="text-sm mb-2">A multitask learning approach.</p>
                        <ul id="sec5-essay-list" class="list-disc list-inside space-y-1 mt-2 text-sm">
                           <li>The model is trained to predict the text transcript of the audio.</li>
                           <li>Special tokens are used in the input to steer the model towards performing specific tasks like language identification, timestamping, and transcription.</li>
                           <li>This multitask format allows a single model to perform diverse speech-processing tasks without needing separate models.</li>
                        </ul>
                    </div>
                </div>
            </section>
            
            <!-- Section 6: Key Applications -->
            <section class="card">
                <h2 id="sec6-title" class="text-3xl font-bold section-heading">6. Key Applications & Use Cases üåü</h2>
                <p id="sec6-p1" class="text-lg text-center mb-8 max-w-4xl mx-auto">Whisper's high accuracy and robustness have unlocked a wide range of applications for automated speech-to-text technology.</p>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-8 text-base">
                    <div>
                        <h3 id="sec6-eng-title" class="subject-category-heading">Media & Content</h3>
                        <ul id="sec6-eng-list" class="list-disc list-inside space-y-2 text-base">
                           <li>Automatic subtitling and captioning for videos.</li>
                           <li>Transcribing podcasts and interviews for articles.</li>
                           <li>Creating searchable archives of audio/video content.</li>
                        </ul>
                    </div>
                    <div>
                        <h3 id="sec6-elec-title" class="subject-category-heading">Business & Productivity</h3>
                        <ul id="sec6-elec-list" class="list-disc list-inside space-y-2 text-base">
                           <li>Transcribing meetings, calls, and webinars.</li>
                           <li>Voice notes and dictation for hands-free typing.</li>
                           <li>Improving accessibility for hearing-impaired individuals.</li>
                        </ul>
                    </div>
                     <div>
                        <h3 id="sec6-naic-title" class="subject-category-heading">Developer Tools</h3>
                        <ul id="sec6-naic-list" class="list-disc list-inside space-y-2 text-base">
                           <li>Building voice-controlled interfaces and applications.</li>
                           <li>Analyzing audio data for sentiment or keywords.</li>
                           <li>Powering voice-based virtual assistants.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Section 7: Performance Benchmarks -->
            <section class="card grid grid-cols-1 lg:grid-cols-2 gap-8 items-center">
                <div>
                     <h2 id="sec7-title" class="text-3xl font-bold section-heading">7. Performance & Benchmarks üéôÔ∏è</h2>
                    <p id="sec7-p1" class="text-lg mb-6">Whisper's performance is typically measured by its Word Error Rate (WER) on various standard academic datasets. A lower WER indicates higher accuracy.</p>
                    <div class="chart-container h-80">
                        <canvas id="interviewQualitiesChart"></canvas>
                    </div>
                </div>
                <div>
                    <h3 id="sec7-qualities-title" class="text-2xl font-bold text-white mb-6 border-b border-[#00f0b5] pb-2">Key Benchmark: Word Error Rate (WER)</h3>
                    <ul id="sec7-qualities-list" class="space-y-4 text-base">
                        <li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üìä</span><div><strong class="text-white">What it is:</strong> WER is the industry standard for measuring ASR accuracy. It calculates the number of errors (substitutions, deletions, insertions) divided by the total number of words.</div></li>
                        <li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üéØ</span><div><strong class="text-white">Robustness:</strong> Whisper achieves state-of-the-art results on many datasets, showing strong performance even on noisy audio and diverse accents where older models struggled.</div></li>
                        <li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üåç</span><div><strong class="text-white">Multilingual Performance:</strong> The model shows remarkably low WER across a wide variety of languages, not just English.</div></li>
                    </ul>
                </div>
            </section>
            
            <!-- Section 8: Best Practices -->
            <section class="card">
                <h2 id="sec8-title" class="text-3xl font-bold section-heading">8. Best Practices for Using Whisper üìà</h2>
                <p id="sec8-p1" class="text-lg mb-8 max-w-4xl mx-auto">To get the highest quality transcripts from Whisper, it's important to follow some best practices for your audio input.</p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div>
                        <h3 id="sec8-steps-title" class="text-2xl font-bold text-white mb-4">üìö Key Principles:</h3>
                        <ol class="relative border-l-4 border-[#00f0b5] pl-6 space-y-8">
                            <li class="ml-4">
                                <div class="absolute w-4 h-4 bg-[#00f0b5] rounded-full -left-2.5 border-4 border-[#1c1c1c]"></div>
                                <h4 id="sec8-step1-title" class="font-semibold text-xl text-white mb-1">High-Quality Audio</h4>
                                <p id="sec8-step1-desc" class="text-base">The cleaner the audio, the better the transcript. Use a good microphone and minimize background noise and echo.</p>
                            </li>
                             <li class="ml-4">
                               <div class="absolute w-4 h-4 bg-[#00f0b5] rounded-full -left-2.5 border-4 border-[#1c1c1c]"></div>
                                <h4 id="sec8-step2-title" class="font-semibold text-xl text-white mb-1">Clear Speech</h4>
                                <p id="sec8-step2-desc" class="text-base">Speak clearly and at a moderate pace. Avoid mumbling or speaking too quickly. Multiple speakers talking over each other will reduce accuracy.</p>
                            </li>
                             <li class="ml-4">
                                <div class="absolute w-4 h-4 bg-[#00f0b5] rounded-full -left-2.5 border-4 border-[#1c1c1c]"></div>
                                <h4 id="sec8-step3-title" class="font-semibold text-xl text-white mb-1">Use the Right Model</h4>
                                <p id="sec8-step3-desc" class="text-base">For best results, use the largest model size (`large-v3`) your hardware can support. For API users, the latest model is always recommended.</p>
                            </li>
                        </ol>
                    </div>
                    <div>
                        <h3 id="sec8-revision-title" class="text-2xl font-bold text-white mb-4">üîÑ API & Prompting:</h3>
                         <ul id="sec8-revision-list" class="list-disc list-inside space-y-3 text-base">
                            <li><strong>Provide Contextual Prompts:</strong> Use the `prompt` parameter in the API to provide a list of correct spellings for specific names, jargon, or acronyms to improve their transcription accuracy.</li>
                            <li><strong>Chunking Long Audio:</strong> For very long audio files, it's best to split them into smaller chunks (e.g., 10-15 minutes) before sending them to the API.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Section 9: Model Versions -->
            <section class="card">
                <h2 id="sec9-title" class="text-3xl font-bold section-heading">9. Model Versions & Evolution üóìÔ∏è</h2>
                <p id="sec9-p1" class="text-lg mb-8">OpenAI has released several versions of the open-source Whisper model, each improving on the last in terms of accuracy, language support, and efficiency.</p>
                <div class="career-path-timeline">
                    <div class="timeline-step">
                        <div class="timeline-dot"></div>
                        <h4 id="sec9-step1-title" class="font-semibold text-xl text-white mb-1">Whisper (v1) Release</h4>
                        <p id="sec9-step1-desc" class="text-base"><strong class="text-gray-400">Timeline:</strong> September 2022. OpenAI open-sources the first Whisper models, setting a new standard for ASR accuracy.</p>
                    </div>
                    <div class="timeline-step">
                        <div class="timeline-dot"></div>
                        <h4 id="sec9-step2-title" class="font-semibold text-xl text-white mb-1">Whisper API Launch</h4>
                        <p id="sec9-step2-desc" class="text-base"><strong class="text-gray-400">Timeline:</strong> March 2023. The highly optimized `large-v2` model is made available through the API, making it easy for developers to use.</p>
                    </div>
                     <div class="timeline-step">
                        <div class="timeline-dot"></div>
                        <h4 id="sec9-step3-title" class="font-semibold text-xl text-white mb-1">Whisper Large-v3 Release</h4>
                        <p id="sec9-step3-desc" class="text-base"><strong class="text-gray-400">Timeline:</strong> November 2023. An updated and improved version with better performance across many languages is released.</p>
                    </div>
                </div>
            </section>

            <!-- Section 10: Mistakes -->
            <section class="card">
                <h2 id="sec10-title" class="text-3xl font-bold section-heading text-center w-full">10. Common Pitfalls & Limitations üö´</h2>
                <p id="sec10-p1" class="text-lg text-center mb-10 max-w-4xl mx-auto">Despite its power, Whisper is not perfect. Understanding its limitations helps in setting the right expectations.</p>
                <div id="sec10-donts-grid" class="grid grid-cols-1 md:grid-cols-2 gap-8 text-base">
                    <div class="group relative p-6 bg-slate-900/50 rounded-lg border-2 border-red-700 shadow-md transition-all duration-300 hover:shadow-xl hover:border-red-500 hover:-translate-y-1">
                        <div class="absolute -top-4 -left-4 bg-red-600 text-white rounded-full w-12 h-12 flex items-center justify-center text-2xl font-bold shadow-lg group-hover:scale-110 transition-transform">‚ùå</div>
                        <div class="ml-10">
                            <strong id="sec10-mistake1-title" class="text-lg text-red-300">Speaker Diarization:</strong>
                            <p id="sec10-mistake1-desc" class="text-red-400 mt-1">Whisper does not natively identify who is speaking (speaker diarization). The output is a single block of text, regardless of the number of speakers.</p>
                        </div>
                    </div>
                    <div class="group relative p-6 bg-slate-900/50 rounded-lg border-2 border-red-700 shadow-md transition-all duration-300 hover:shadow-xl hover:border-red-500 hover:-translate-y-1">
                         <div class="absolute -top-4 -left-4 bg-red-600 text-white rounded-full w-12 h-12 flex items-center justify-center text-2xl font-bold shadow-lg group-hover:scale-110 transition-transform">‚ùå</div>
                        <div class="ml-10">
                            <strong id="sec10-mistake2-title" class="text-lg text-red-300">Real-time Transcription:</strong>
                            <p id="sec10-mistake2-desc" class="text-red-400 mt-1">The open-source models are not optimized for real-time transcription out-of-the-box and can have high latency without specialized engineering.</p>
                        </div>
                    </div>
                     <div class="group relative p-6 bg-slate-900/50 rounded-lg border-2 border-red-700 shadow-md transition-all duration-300 hover:shadow-xl hover:border-red-500 hover:-translate-y-1">
                         <div class="absolute -top-4 -left-4 bg-red-600 text-white rounded-full w-12 h-12 flex items-center justify-center text-2xl font-bold shadow-lg group-hover:scale-110 transition-transform">‚ùå</div>
                        <div class="ml-10">
                            <strong id="sec10-mistake3-title" class="text-lg text-red-300">Hallucinating Text:</strong>
                            <p id="sec10-mistake3-desc" class="text-red-400 mt-1">On silent or ambiguous audio segments, the model can sometimes "hallucinate" and generate repetitive or nonsensical text.</p>
                        </div>
                    </div>
                     <div class="group relative p-6 bg-slate-900/50 rounded-lg border-2 border-red-700 shadow-md transition-all duration-300 hover:shadow-xl hover:border-red-500 hover:-translate-y-1">
                         <div class="absolute -top-4 -left-4 bg-red-600 text-white rounded-full w-12 h-12 flex items-center justify-center text-2xl font-bold shadow-lg group-hover:scale-110 transition-transform">‚ùå</div>
                        <div class="ml-10">
                            <strong id="sec10-mistake4-title" class="text-lg text-red-300">Struggles with Jargon:</strong>
                            <p id="sec10-mistake4-desc" class="text-red-400 mt-1">While robust, it can still make errors on highly specific technical jargon, unusual names, or acronyms not well-represented in its training data.</p>
                        </div>
                    </div>
                </div>
            </section>
            
            <!-- Section 11: How to Access -->
            <section class="card">
                <h2 id="sec11-title" class="text-3xl font-bold section-heading">11. How to Access & Use üè´</h2>
                <p id="sec11-p1" class="text-lg text-center mb-8 max-w-4xl mx-auto">There are multiple ways to use Whisper, from simple API calls to running the model on your own machine.</p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div>
                        <h3 id="sec11-gov-title" class="subject-category-heading">üìö Via OpenAI API</h3>
                        <ul id="sec11-gov-list" class="list-disc list-inside space-y-2 text-base">
                           <li>The easiest and most efficient method. Simply sign up for an API key.</li>
                           <li>Send an audio file to the API endpoint and receive the text transcript back.</li>
                           <li>No need to manage complex hardware or software dependencies.</li>
                        </ul>
                    </div>
                    <div>
                        <h3 id="sec11-pvt-title" class="subject-category-heading">üíª Open Source</h3>
                        <p id="sec11-pvt-p1" class="text-base mb-2">For those with technical expertise.</p>
                        <ul id="sec11-pvt-list" class="list-disc list-inside space-y-2 text-base">
                            <li>Download the model and code from the official OpenAI GitHub repository.</li>
                            <li>Requires a powerful computer with a modern GPU (like NVIDIA) for reasonable performance.</li>
                            <li>Gives you full control over the model and its usage.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Section 12: The Future -->
            <section class="card">
                <h2 id="sec12-title" class="text-3xl font-bold section-heading">12. The Future of Speech Recognition üöÄ</h2>
                <p id="sec12-p1" class="text-lg mb-6">Whisper has set a new baseline for ASR. The future will likely see even more advanced capabilities, moving beyond simple transcription to a deeper understanding of spoken communication.</p>
                <button id="sec12-career-btn" class="modal-action-button mt-4 inline-block" data-modal-target="careerGrowthModal">View Expected Advancements</button>
            </section>

            <!-- Section 13: Core Concepts -->
            <section class="card bg-gradient-to-br from-[#1f2937] to-[#101827]">
                <h2 id="sec13-title" class="text-3xl font-bold section-heading">13. Core ASR Concepts üìö</h2>
                <p id="sec13-p1" class="text-lg text-center mb-10 max-w-4xl mx-auto">Understanding these fundamental concepts of Automatic Speech Recognition (ASR) helps in appreciating the technology behind Whisper.</p>
                <div id="syllabus-material-grid" class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div class="bg-[#101827] p-6 rounded-lg shadow-lg border border-slate-700">
                        <h3 id="syllabus-oir-title" class="subject-category-heading">Fundamental Ideas</h3>
                        <div id="syllabus-oir-list" class="space-y-4">
                            <!-- Content via JS -->
                        </div>
                    </div>
                    <div class="bg-[#101827] p-6 rounded-lg shadow-lg border border-slate-700">
                        <h3 id="syllabus-ppdt-title" class="subject-category-heading">Architectural Components</h3>
                        <div id="syllabus-ppdt-list" class="space-y-4">
                            <!-- Content via JS -->
                        </div>
                    </div>
                </div>
            </section>

        </main>

        <footer class="text-center mt-16 border-t-2 pt-8 border-purple-500/20">
            <p id="footer-text" class="text-slate-400 text-lg font-medium">&copy; 2025 | The Future of Speech is Here.</p>
        </footer>

    </div>

    <!-- Modals -->
    <div id="prelimsMainModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <h3 id="prelims-modal-title" class="text-2xl font-bold text-white mb-4">Input: Audio File</h3>
            <p id="prelims-modal-p1">The process begins with an audio file (e.g., MP3, WAV, M4A). Whisper automatically breaks this audio down into 30-second segments. Each segment is then converted into a spectrogram, a visual representation of the spectrum of frequencies of a signal as it varies with time.</p>
        </div>
    </div>

    <div id="mainsMainModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <h3 id="mains-modal-title" class="text-2xl font-bold text-white mb-4">Whisper Model: Encoder-Decoder</h3>
            <p id="mains-modal-p1">The spectrogram is passed to an encoder which creates a numerical representation of the audio. This representation is then passed to a decoder, which has been trained to predict the corresponding text transcript, including capitalization and punctuation. It performs tasks like language identification and translation at this stage.</p>
        </div>
    </div>

    <div id="interviewModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <h3 id="interview-modal-title" class="text-2xl font-bold text-white mb-4">Output: Text Transcript</h3>
            <p id="interview-modal-p1" class="text-base mb-3">The decoder generates the final text output. A special filtering mechanism is used to handle repetitive transcriptions or hallucinations. The outputs from all the 30-second chunks are then stitched together to form the complete, final transcript of the original audio file.</p>
        </div>
    </div>

    <!-- Post Detail Modal -->
    <div id="postDetailModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <div class="flex items-center mb-4">
                <div id="postDetailIcon" class="text-5xl mr-4"></div>
                <h3 id="postDetailTitle" class="text-3xl font-bold text-white"></h3>
            </div>
            <p id="postDetailDescription" class="text-lg text-indigo-200 leading-relaxed"></p>
        </div>
    </div>
    
    <div id="careerGrowthModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <h3 id="career-modal-title" class="text-2xl font-bold text-white mb-6">The Future of Speech Recognition</h3>
            <div id="careerPathContainer" class="career-path-timeline"></div>
        </div>
    </div>


    <script>
        document.addEventListener('DOMContentLoaded', () => {
            let interviewChartInstance;
            let currentLang = 'en';

            const serviceDetailsData = {
                'en': {
                    'transcription': { 
                        name: 'Multilingual Transcription', 
                        icon: 'üåê',
                        description: 'Whisper can accurately transcribe speech in nearly 100 languages, making it a powerful tool for global communication and content creation.',
                        cta: 'Learn More'
                    },
                    'translation': { 
                        name: 'Speech-to-English Translation', 
                        icon: 'üîÑ',
                        description: 'The model can take speech in any of its supported languages and directly translate it into written English text, streamlining cross-lingual workflows.',
                        cta: 'Learn More'
                    },
                    'robustness': { 
                        name: 'Robustness to Noise', 
                        icon: 'üîä',
                        description: 'Trained on a diverse dataset, Whisper shows remarkable performance in transcribing audio with significant background noise, accents, and technical jargon.',
                        cta: 'Learn More'
                    }
                },
                'hi': {
                    'transcription': { 
                        name: '‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§®', 
                        icon: 'üåê',
                        description: '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§≤‡§ó‡§≠‡§ó 100 ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§∑‡§£ ‡§ï‡§æ ‡§∏‡§ü‡•Ä‡§ï ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§á‡§∏‡•á ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§î‡§∞ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§â‡§™‡§ï‡§∞‡§£ ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à‡•§',
                        cta: '‡§î‡§∞ ‡§ú‡§æ‡§®‡•á‡§Ç'
                    },
                    'translation': { 
                        name: '‡§≠‡§æ‡§∑‡§£-‡§∏‡•á-‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶', 
                        icon: 'üîÑ',
                        description: '‡§Æ‡•â‡§°‡§≤ ‡§Ö‡§™‡§®‡•Ä ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§∑‡§£ ‡§≤‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§∏‡•Ä‡§ß‡•á ‡§á‡§∏‡•á ‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§™‡§æ‡§† ‡§Æ‡•á‡§Ç ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§ï‡•ç‡§∞‡•â‡§∏-‡§≤‡§ø‡§Ç‡§ó‡•Å‡§Ö‡§≤ ‡§µ‡§∞‡•ç‡§ï‡§´‡§º‡•ç‡§≤‡•ã ‡§∏‡•Å‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§',
                        cta: '‡§î‡§∞ ‡§ú‡§æ‡§®‡•á‡§Ç'
                    },
                    'robustness': { 
                        name: '‡§∂‡•ã‡§∞ ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø ‡§Æ‡§ú‡§¨‡•Ç‡§§‡•Ä', 
                        icon: 'üîä',
                        description: '‡§è‡§ï ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§, ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•É‡§∑‡•ç‡§†‡§≠‡•Ç‡§Æ‡§ø ‡§∂‡•ã‡§∞, ‡§≤‡§π‡§ú‡•á ‡§î‡§∞ ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∂‡§¨‡•ç‡§¶‡§ú‡§æ‡§≤ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ‡§®‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§¶‡§ø‡§ñ‡§æ‡§§‡§æ ‡§π‡•à‡•§',
                        cta: '‡§î‡§∞ ‡§ú‡§æ‡§®‡•á‡§Ç'
                    }
                }
            };
            
            const careerPathData = {
                'en': {
                    path: [
                        { rank: "Real-time, Low Latency", desc: "Future models will be highly optimized for instant, real-time transcription and translation, enabling seamless live applications." },
                        { rank: "Speaker Diarization", desc: "AI will be able to accurately identify and label different speakers in a single audio file ('Who spoke what?')." },
                        { rank: "Emotional & Tonal Understanding", desc: "Models will go beyond text to understand the emotion, tone, and intent behind the spoken words." },
                        { rank: "Voice Cloning & Generation", desc: "Realistic text-to-speech capabilities that can clone a person's voice from a small audio sample." },
                        { rank: "Deeper Integration", desc: "ASR will become a standard, invisible feature in most applications, from operating systems to wearable devices." }
                    ]
                },
                'hi': {
                    path: [
                        { rank: "‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∏‡§Æ‡§Ø, ‡§ï‡§Æ ‡§µ‡§ø‡§≤‡§Ç‡§¨‡§§‡§æ", desc: "‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•á ‡§Æ‡•â‡§°‡§≤ ‡§§‡§§‡•ç‡§ï‡§æ‡§≤, ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§π‡•ã‡§Ç‡§ó‡•á, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§®‡§ø‡§∞‡•ç‡§¨‡§æ‡§ß ‡§≤‡§æ‡§á‡§µ ‡§è‡§™‡•ç‡§≤‡§ø‡§ï‡•á‡§∂‡§® ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§π‡•ã‡§Ç‡§ó‡•á‡•§" },
                        { rank: "‡§µ‡§ï‡•ç‡§§‡§æ ‡§°‡§æ‡§Ø‡§∞‡§æ‡§á‡§ú‡•á‡§∂‡§®", desc: "‡§è‡§Ü‡§à ‡§è‡§ï ‡§π‡•Ä ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§º‡§æ‡§á‡§≤ ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§µ‡§ï‡•ç‡§§‡§æ‡§ì‡§Ç ‡§ï‡•Ä ‡§∏‡§ü‡•Ä‡§ï ‡§™‡§π‡§ö‡§æ‡§® ‡§î‡§∞ ‡§≤‡•á‡§¨‡§≤‡§ø‡§Ç‡§ó ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§π‡•ã‡§ó‡§æ ('‡§ï‡§ø‡§∏‡§®‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§π‡§æ?')‡•§" },
                        { rank: "‡§≠‡§æ‡§µ‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§î‡§∞ ‡§§‡§æ‡§®‡§µ‡§æ‡§≤‡§æ ‡§∏‡§Æ‡§ù", desc: "‡§Æ‡•â‡§°‡§≤ ‡§¨‡•ã‡§≤‡•á ‡§ó‡§è ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•á ‡§™‡•Ä‡§õ‡•á ‡§ï‡•Ä ‡§≠‡§æ‡§µ‡§®‡§æ, ‡§∏‡•ç‡§µ‡§∞ ‡§î‡§∞ ‡§á‡§∞‡§æ‡§¶‡•á ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§æ‡§† ‡§∏‡•á ‡§™‡§∞‡•á ‡§ú‡§æ‡§è‡§Ç‡§ó‡•á‡•§" },
                        { rank: "‡§Ü‡§µ‡§æ‡§ú ‡§ï‡•ç‡§≤‡•ã‡§®‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§™‡•Ä‡§¢‡§º‡•Ä", desc: "‡§Ø‡§•‡§æ‡§∞‡•ç‡§•‡§µ‡§æ‡§¶‡•Ä ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü-‡§ü‡•Ç-‡§∏‡•ç‡§™‡•Ä‡§ö ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Ç ‡§ú‡•ã ‡§è‡§ï ‡§õ‡•ã‡§ü‡•á ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§®‡§Æ‡•Ç‡§®‡•á ‡§∏‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú ‡§ï‡§æ ‡§ï‡•ç‡§≤‡•ã‡§® ‡§¨‡§®‡§æ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç‡•§" },
                        { rank: "‡§ó‡§π‡§∞‡§æ ‡§è‡§ï‡•Ä‡§ï‡§∞‡§£", desc: "‡§è‡§è‡§∏‡§Ü‡§∞ ‡§ë‡§™‡§∞‡•á‡§ü‡§ø‡§Ç‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§™‡§π‡§®‡§®‡•á ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§§‡§ï ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§Ç‡§∂ ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§Æ‡§æ‡§®‡§ï, ‡§Ö‡§¶‡•É‡§∂‡•ç‡§Ø ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§¨‡§® ‡§ú‡§æ‡§è‡§ó‡§æ‡•§" }
                    ]
                }
            };

            const translations = {
                'en': {
                    'header-title': 'üéôÔ∏è OpenAI Whisper: The Ultimate Guide üéôÔ∏è',
                    'header-subtitle': 'Unlocking the Power of Automated Speech Recognition',
                    'sec1-title': '1. What is OpenAI Whisper? üí°',
                    'sec1-p1': 'OpenAI Whisper is a state-of-the-art Automatic Speech Recognition (ASR) model. Unlike general-purpose models like GPT, Whisper is specifically designed for one primary task: converting spoken language into written text with remarkable accuracy. Trained on a vast and diverse dataset of audio, it achieves human-level robustness and accuracy across a wide range of languages, accents, and noisy environments, making it a powerful tool for transcription and translation.',
                    'sec2-title': '2. How Whisper Works üéØ',
                    'sec2-p1': 'Whisper uses a sophisticated end-to-end Transformer architecture to process audio and predict the corresponding text sequence.',
                    'sec2-step1-title': 'Input', 'sec2-step1-name': 'Audio File', 'sec2-step1-desc': 'Audio is split into 30-second chunks',
                    'sec2-step2-title': 'Whisper Model', 'sec2-step2-name': 'Encoder-Decoder', 'sec2-step2-desc': 'Audio is processed and text is predicted',
                    'sec2-step3-title': 'Output', 'sec2-step3-name': 'Text Transcript', 'sec2-step3-desc': 'The final transcribed text is generated',
                    'sec3-title': '3. Who Can Use It? ‚úÖ',
                    'sec3-p1': 'Whisper is designed to be accessible to a broad audience, from individual developers to large corporations.',
                    'sec3-age-title': 'Developers & Researchers:', 'sec3-age-desc': 'The primary users, integrating Whisper into applications for transcription, translation, and voice-enabled features.',
                    'sec3-edu-title': 'Content Creators & Media:', 'sec3-edu-desc': 'Used for creating accurate subtitles for videos, transcribing podcasts, and generating text from interviews.',
                    'sec3-attempts-title': 'Primary Platforms üìä',
                    'sec3-agerelax-list': '<li><strong>OpenAI API:</strong> The easiest way to use the latest, most optimized Whisper model on a pay-as-you-go basis.</li><li><strong>Open Source:</strong> OpenAI has open-sourced the Whisper models and code, allowing anyone to run them on their own hardware.</li><li><strong>Third-Party Services:</strong> Numerous applications and services have integrated Whisper to offer transcription features.</li>',
                    'sec4-title': '4. Core Capabilities üìö',
                    'sec4-p1': 'Whisper\'s architecture allows it to perform multiple complex speech-processing tasks simultaneously.',
                    'gs1-title': 'Transcription',
                    'gs2-title': 'Translation',
                    'gs3-title': 'Language ID',
                    'gs4-title': 'Timestamping',
                    'sec5-title': '5. How was Whisper Trained? üèõÔ∏è',
                    'sec5-p1': 'Whisper\'s robustness comes from its unique training on a massive and incredibly diverse dataset, which distinguishes it from traditional ASR systems.',
                    'sec5-hindi-title': '1. The Dataset', 'sec5-hindi-p1': 'A large and diverse supervised dataset.', 'sec5-hindi-list': '<li>Trained on **680,000 hours** of multilingual and multitask supervised data collected from the web.</li><li>This diversity improves robustness to different accents, background noise, and technical language.</li><li>About one-third of the audio data is non-English, enabling powerful multilingual capabilities.</li>',
                    'sec5-essay-title': '2. The Training Process', 'sec5-essay-p1': 'A multitask learning approach.', 'sec5-essay-list': '<li>The model is trained to predict the text transcript of the audio.</li><li>Special tokens are used in the input to steer the model towards performing specific tasks like language identification, timestamping, and transcription.</li><li>This multitask format allows a single model to perform diverse speech-processing tasks without needing separate models.</li>',
                    'sec6-title': '6. Key Applications & Use Cases üåü',
                    'sec6-p1': 'Whisper\'s high accuracy and robustness have unlocked a wide range of applications for automated speech-to-text technology.',
                    'sec6-eng-title': 'Media & Content', 'sec6-eng-list': '<li>Automatic subtitling and captioning for videos.</li><li>Transcribing podcasts and interviews for articles.</li><li>Creating searchable archives of audio/video content.</li>',
                    'sec6-elec-title': 'Business & Productivity', 'sec6-elec-list': '<li>Transcribing meetings, calls, and webinars.</li><li>Voice notes and dictation for hands-free typing.</li><li>Improving accessibility for hearing-impaired individuals.</li>',
                    'sec6-naic-title': 'Developer Tools', 'sec6-naic-list': '<li>Building voice-controlled interfaces and applications.</li><li>Analyzing audio data for sentiment or keywords.</li><li>Powering voice-based virtual assistants.</li>',
                    'sec7-title': '7. Performance & Benchmarks üéôÔ∏è',
                    'sec7-p1': 'Whisper\'s performance is typically measured by its Word Error Rate (WER) on various standard academic datasets. A lower WER indicates higher accuracy.',
                    'sec7-qualities-title': 'Key Benchmark: Word Error Rate (WER)',
                    'sec7-qualities-list': '<li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üìä</span><div><strong class="text-white">What it is:</strong> WER is the industry standard for measuring ASR accuracy. It calculates the number of errors (substitutions, deletions, insertions) divided by the total number of words.</div></li><li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üéØ</span><div><strong class="text-white">Robustness:</strong> Whisper achieves state-of-the-art results on many datasets, showing strong performance even on noisy audio and diverse accents where older models struggled.</div></li><li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üåç</span><div><strong class="text-white">Multilingual Performance:</strong> The model shows remarkably low WER across a wide variety of languages, not just English.</div></li>',
                    'sec8-title': '8. Best Practices for Using Whisper üìà',
                    'sec8-p1': 'To get the highest quality transcripts from Whisper, it\'s important to follow some best practices for your audio input.',
                    'sec8-steps-title': 'üìö Key Principles:',
                    'sec8-step1-title': 'High-Quality Audio', 'sec8-step1-desc': 'The cleaner the audio, the better the transcript. Use a good microphone and minimize background noise and echo.',
                    'sec8-step2-title': 'Clear Speech', 'sec8-step2-desc': 'Speak clearly and at a moderate pace. Avoid mumbling or speaking too quickly. Multiple speakers talking over each other will reduce accuracy.',
                    'sec8-step3-title': 'Use the Right Model', 'sec8-step3-desc': 'For best results, use the largest model size (`large-v3`) your hardware can support. For API users, the latest model is always recommended.',
                    'sec8-revision-title': 'üîÑ API & Prompting:',
                    'sec8-revision-list': '<li><strong>Provide Contextual Prompts:</strong> Use the `prompt` parameter in the API to provide a list of correct spellings for specific names, jargon, or acronyms to improve their transcription accuracy.</li><li><strong>Chunking Long Audio:</strong> For very long audio files, it\'s best to split them into smaller chunks (e.g., 10-15 minutes) before sending them to the API.</li>',
                    'sec9-title': '9. Model Versions & Evolution üóìÔ∏è',
                    'sec9-p1': 'OpenAI has released several versions of the open-source Whisper model, each improving on the last in terms of accuracy, language support, and efficiency.',
                    'sec9-step1-title': 'Whisper (v1) Release', 'sec9-step1-desc': '<strong>Timeline:</strong> September 2022. OpenAI open-sources the first Whisper models, setting a new standard for ASR accuracy.',
                    'sec9-step2-title': 'Whisper API Launch', 'sec9-step2-desc': '<strong>Timeline:</strong> March 2023. The highly optimized `large-v2` model is made available through the API, making it easy for developers to use.',
                    'sec9-step3-title': 'Whisper Large-v3 Release', 'sec9-step3-desc': '<strong>Timeline:</strong> November 2023. An updated and improved version with better performance across many languages is released.',
                    'sec10-title': '10. Common Pitfalls & Limitations üö´',
                    'sec10-p1': 'Despite its power, Whisper is not perfect. Understanding its limitations helps in setting the right expectations.',
                    'sec10-mistake1-title': 'Speaker Diarization:', 'sec10-mistake1-desc': 'Whisper does not natively identify who is speaking (speaker diarization). The output is a single block of text, regardless of the number of speakers.',
                    'sec10-mistake2-title': 'Real-time Transcription:', 'sec10-mistake2-desc': 'The open-source models are not optimized for real-time transcription out-of-the-box and can have high latency without specialized engineering.',
                    'sec10-mistake3-title': 'Hallucinating Text:', 'sec10-mistake3-desc': 'On silent or ambiguous audio segments, the model can sometimes "hallucinate" and generate repetitive or nonsensical text.',
                    'sec10-mistake4-title': 'Struggles with Jargon:', 'sec10-mistake4-desc': 'While robust, it can still make errors on highly specific technical jargon, unusual names, or acronyms not well-represented in its training data.',
                    'sec11-title': '11. How to Access & Use üè´',
                    'sec11-p1': 'There are multiple ways to use Whisper, from simple API calls to running the model on your own machine.',
                    'sec11-gov-title': 'üìö Via OpenAI API', 'sec11-gov-list': '<li>The easiest and most efficient method. Simply sign up for an API key.</li><li>Send an audio file to the API endpoint and receive the text transcript back.</li><li>No need to manage complex hardware or software dependencies.</li>',
                    'sec11-pvt-title': 'üíª Open Source', 'sec11-pvt-p1': 'For those with technical expertise.', 'sec11-pvt-list': '<li>Download the model and code from the official OpenAI GitHub repository.</li><li>Requires a powerful computer with a modern GPU (like NVIDIA) for reasonable performance.</li><li>Gives you full control over the model and its usage.</li>',
                    'sec12-title': '12. The Future of Speech Recognition üöÄ',
                    'sec12-p1': 'Whisper has set a new baseline for ASR. The future will likely see even more advanced capabilities, moving beyond simple transcription to a deeper understanding of spoken communication.',
                    'sec12-career-btn': 'View Expected Advancements',
                    'sec13-title': '13. Core ASR Concepts üìö',
                    'sec13-p1': 'Understanding these fundamental concepts of Automatic Speech Recognition (ASR) helps in appreciating the technology behind Whisper.',
                    'syllabus-oir-title': 'Fundamental Ideas',
                    'syllabus-oir-list': '<div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üîä</span><div class="flex-grow">Phonemes & Spectrograms</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">Notes</button><button class="lectures-btn">Lectures</button></div></div><div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üìä</span><div class="flex-grow">Word Error Rate (WER)</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">Notes</button><button class="lectures-btn">Lectures</button></div></div>',
                    'syllabus-ppdt-title': 'Architectural Components',
                    'syllabus-ppdt-list': '<div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">‚û°Ô∏è</span><div class="flex-grow">Encoder-Decoder Models</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">Notes</button><button class="lectures-btn">Lectures</button></div></div><div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üß†</span><div class="flex-grow">Transformer & Attention</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">Notes</button><button class="lectures-btn">Lectures</button></div></div>',
                    'footer-text': '&copy; 2025 | The Future of Speech is Here.',
                    'interviewChartData': {
                        labels: ['Clean Audio', 'Noisy Audio', 'Accented Speech', 'Translation'],
                        data: [98, 92, 90, 95] // Example data representing high accuracy %
                    }
                },
                'hi': {
                    'header-title': 'üéôÔ∏è ‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞: ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§ó‡§æ‡§á‡§° üéôÔ∏è',
                    'header-subtitle': '‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§µ‡§æ‡§ï‡•ç ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•ã ‡§Ö‡§®‡§≤‡•â‡§ï ‡§ï‡§∞‡§®‡§æ',
                    'sec1-title': '1. ‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à? üí°',
                    'sec1-p1': '‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§è‡§ï ‡§Ö‡§§‡•ç‡§Ø‡§æ‡§ß‡•Å‡§®‡§ø‡§ï ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§µ‡§æ‡§ï‡•ç ‡§™‡§π‡§ö‡§æ‡§® (‡§è‡§è‡§∏‡§Ü‡§∞) ‡§Æ‡•â‡§°‡§≤ ‡§π‡•à‡•§ ‡§ú‡•Ä‡§™‡•Ä‡§ü‡•Ä ‡§ú‡•à‡§∏‡•á ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø-‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§µ‡§ø‡§™‡§∞‡•Ä‡§§, ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§è‡§ï ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à: ‡§¨‡•ã‡§≤‡•Ä ‡§ú‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§ï‡•ã ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ‡§®‡•Ä‡§Ø ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§™‡§æ‡§† ‡§Æ‡•á‡§Ç ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ‡•§ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•á ‡§è‡§ï ‡§µ‡§ø‡§∂‡§æ‡§≤ ‡§î‡§∞ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§, ‡§Ø‡§π ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç, ‡§≤‡§π‡§ú‡•á ‡§î‡§∞ ‡§∂‡•ã‡§∞ ‡§µ‡§æ‡§≤‡•á ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§ï‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§Æ‡•á‡§Ç ‡§Æ‡§æ‡§®‡§µ-‡§∏‡•ç‡§§‡§∞ ‡§ï‡•Ä ‡§Æ‡§ú‡§¨‡•Ç‡§§‡•Ä ‡§î‡§∞ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§á‡§∏‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§â‡§™‡§ï‡§∞‡§£ ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à‡•§',
                    'sec2-title': '2. ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•à‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à üéØ',
                    'sec2-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§™‡§æ‡§† ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ ‡§ï‡•Ä ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø‡§µ‡§æ‡§£‡•Ä ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§™‡§∞‡§ø‡§∑‡•ç‡§ï‡•É‡§§ ‡§è‡§Ç‡§°-‡§ü‡•Ç-‡§è‡§Ç‡§° ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§´‡§æ‡§∞‡•ç‡§Æ‡§∞ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§',
                    'sec2-step1-title': '‡§á‡§®‡§™‡•Å‡§ü', 'sec2-step1-name': '‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§º‡§æ‡§á‡§≤', 'sec2-step1-desc': '‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã 30-‡§∏‡•á‡§ï‡§Ç‡§° ‡§ï‡•á ‡§π‡§ø‡§∏‡•ç‡§∏‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§æ‡§ú‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à',
                    'sec2-step2-title': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤', 'sec2-step2-name': '‡§è‡§®‡§ï‡•ã‡§°‡§∞-‡§°‡§ø‡§ï‡•ã‡§°‡§∞', 'sec2-step2-desc': '‡§ë‡§°‡§ø‡§Ø‡•ã ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§ø‡§§ ‡§π‡•ã‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§™‡§æ‡§† ‡§ï‡•Ä ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø‡§µ‡§æ‡§£‡•Ä ‡§ï‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à',
                    'sec2-step3-title': '‡§Ü‡§â‡§ü‡§™‡•Å‡§ü', 'sec2-step3-name': '‡§™‡§æ‡§† ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ', 'sec2-step3-desc': '‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§ø‡§§ ‡§™‡§æ‡§† ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§π‡•ã‡§§‡§æ ‡§π‡•à',
                    'sec3-title': '3. ‡§á‡§∏‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•å‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à? ‚úÖ',
                    'sec3-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§°‡•á‡§µ‡§≤‡§™‡§∞‡•ç‡§∏ ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§¨‡§°‡§º‡•á ‡§®‡§ø‡§ó‡§Æ‡•ã‡§Ç ‡§§‡§ï, ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§¶‡§∞‡•ç‡§∂‡§ï ‡§µ‡§∞‡•ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•Å‡§≤‡§≠ ‡§π‡•ã‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§',
                    'sec3-age-title': '‡§°‡•á‡§µ‡§≤‡§™‡§∞‡•ç‡§∏ ‡§î‡§∞ ‡§∂‡•ã‡§ß‡§ï‡§∞‡•ç‡§§‡§æ:', 'sec3-age-desc': '‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ, ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§®, ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§î‡§∞ ‡§Ü‡§µ‡§æ‡§ú-‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•ã ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§',
                    'sec3-edu-title': '‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§§‡§æ ‡§î‡§∞ ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ:', 'sec3-edu-desc': '‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§ü‡•Ä‡§ï ‡§â‡§™‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ï ‡§¨‡§®‡§æ‡§®‡•á, ‡§™‡•â‡§°‡§ï‡§æ‡§∏‡•ç‡§ü ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ ‡§∏‡§æ‡§ï‡•ç‡§∑‡§æ‡§§‡•ç‡§ï‡§æ‡§∞‡•ã‡§Ç ‡§∏‡•á ‡§™‡§æ‡§† ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§',
                    'sec3-attempts-title': '‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ üìä',
                    'sec3-agerelax-list': '<li><strong>‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§è‡§™‡•Ä‡§Ü‡§à:</strong> ‡§®‡§µ‡•Ä‡§®‡§§‡§Æ, ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ü‡§∏‡§æ‡§® ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§™‡•á-‡§è‡§ú‡§º-‡§Ø‡•Ç-‡§ó‡•ã ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§π‡•à‡•§</li><li><strong>‡§ì‡§™‡§® ‡§∏‡•ã‡§∞‡•ç‡§∏:</strong> ‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§®‡•á ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§ï‡•ã‡§° ‡§ï‡•ã ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§Ö‡§™‡§®‡•á ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§™‡§∞ ‡§ö‡§≤‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§</li><li><strong>‡§§‡•É‡§§‡•Ä‡§Ø-‡§™‡§ï‡•ç‡§∑ ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç:</strong> ‡§ï‡§à ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§î‡§∞ ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§®‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Å ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•ã ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§</li>',
                    'sec4-title': '4. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Ç üìö',
                    'sec4-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡§æ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§á‡§∏‡•á ‡§è‡§ï ‡§∏‡§æ‡§• ‡§ï‡§à ‡§ú‡§ü‡§ø‡§≤ ‡§≠‡§æ‡§∑‡§£-‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§',
                    'gs1-title': '‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§®',
                    'gs2-title': '‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶',
                    'gs3-title': '‡§≠‡§æ‡§∑‡§æ ‡§Ü‡§à‡§°‡•Ä',
                    'gs4-title': '‡§ü‡§æ‡§á‡§Æ‡§∏‡•ç‡§ü‡•à‡§Æ‡•ç‡§™‡§ø‡§Ç‡§ó',
                    'sec5-title': '5. ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•ã ‡§ï‡•à‡§∏‡•á ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ? üèõÔ∏è',
                    'sec5-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•Ä ‡§Æ‡§ú‡§¨‡•Ç‡§§‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∂‡§æ‡§≤ ‡§î‡§∞ ‡§Ö‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§™‡§∞ ‡§á‡§∏‡§ï‡•á ‡§Ö‡§¶‡•ç‡§µ‡§ø‡§§‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§∏‡•á ‡§Ü‡§§‡•Ä ‡§π‡•à, ‡§ú‡•ã ‡§á‡§∏‡•á ‡§™‡§æ‡§∞‡§Ç‡§™‡§∞‡§ø‡§ï ‡§è‡§è‡§∏‡§Ü‡§∞ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡•á ‡§Ö‡§≤‡§ó ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§',
                    'sec5-hindi-title': '1. ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü', 'sec5-hindi-p1': '‡§è‡§ï ‡§¨‡§°‡§º‡§æ ‡§î‡§∞ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§™‡§∞‡•ç‡§Ø‡§µ‡•á‡§ï‡•ç‡§∑‡§ø‡§§ ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü‡•§', 'sec5-hindi-list': '<li>‡§µ‡•á‡§¨ ‡§∏‡•á ‡§è‡§ï‡§§‡•ç‡§∞ ‡§ï‡§ø‡§è ‡§ó‡§è **680,000 ‡§ò‡§Ç‡§ü‡•á** ‡§ï‡•á ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§î‡§∞ ‡§Æ‡§≤‡•ç‡§ü‡•Ä‡§ü‡§æ‡§∏‡•ç‡§ï ‡§™‡§∞‡•ç‡§Ø‡§µ‡•á‡§ï‡•ç‡§∑‡§ø‡§§ ‡§°‡•á‡§ü‡§æ ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§‡•§</li><li>‡§Ø‡§π ‡§µ‡§ø‡§µ‡§ø‡§ß‡§§‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§≤‡§π‡§ú‡•á, ‡§™‡•É‡§∑‡•ç‡§†‡§≠‡•Ç‡§Æ‡§ø ‡§∂‡•ã‡§∞ ‡§î‡§∞ ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø ‡§Æ‡§ú‡§¨‡•Ç‡§§‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§</li><li>‡§≤‡§ó‡§≠‡§ó ‡§è‡§ï-‡§§‡§ø‡§π‡§æ‡§à ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§°‡•á‡§ü‡§æ ‡§ó‡•à‡§∞-‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§π‡•à, ‡§ú‡•ã ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§</li>',
                    'sec5-essay-title': '2. ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ', 'sec5-essay-p1': '‡§è‡§ï ‡§Æ‡§≤‡•ç‡§ü‡•Ä‡§ü‡§æ‡§∏‡•ç‡§ï ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§ï‡§æ ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£‡•§', 'sec5-essay-list': '<li>‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•á ‡§™‡§æ‡§† ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ ‡§ï‡•Ä ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø‡§µ‡§æ‡§£‡•Ä ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§</li><li>‡§á‡§®‡§™‡•Å‡§ü ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§ü‡•ã‡§ï‡§® ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§≠‡§æ‡§∑‡§æ ‡§™‡§π‡§ö‡§æ‡§®, ‡§ü‡§æ‡§á‡§Æ‡§∏‡•ç‡§ü‡•à‡§Æ‡•ç‡§™‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§ú‡•à‡§∏‡•á ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§ì‡§∞ ‡§≤‡•á ‡§ú‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§</li><li>‡§Ø‡§π ‡§Æ‡§≤‡•ç‡§ü‡•Ä‡§ü‡§æ‡§∏‡•ç‡§ï ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§è‡§ï ‡§π‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§≠‡§æ‡§∑‡§£-‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§</li>',
                    'sec6-title': '6. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•á ‡§Æ‡§æ‡§Æ‡§≤‡•á üåü',
                    'sec6-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•Ä ‡§â‡§ö‡•ç‡§ö ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§î‡§∞ ‡§Æ‡§ú‡§¨‡•Ç‡§§‡•Ä ‡§®‡•á ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§≠‡§æ‡§∑‡§£-‡§∏‡•á-‡§™‡§æ‡§† ‡§™‡•ç‡§∞‡•å‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§ñ‡•ã‡§≤ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à‡•§',
                    'sec6-eng-title': '‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§î‡§∞ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä', 'sec6-eng-list': '<li>‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§â‡§™‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ï ‡§î‡§∞ ‡§ï‡•à‡§™‡•ç‡§∂‡§®‡§ø‡§Ç‡§ó‡•§</li><li>‡§≤‡•á‡§ñ‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•â‡§°‡§ï‡§æ‡§∏‡•ç‡§ü ‡§î‡§∞ ‡§∏‡§æ‡§ï‡•ç‡§∑‡§æ‡§§‡•ç‡§ï‡§æ‡§∞‡•ã‡§Ç ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§®‡•§</li><li>‡§ë‡§°‡§ø‡§Ø‡•ã/‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§ï‡•á ‡§ñ‡•ã‡§ú ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§Ö‡§≠‡§ø‡§≤‡•á‡§ñ‡§æ‡§ó‡§æ‡§∞ ‡§¨‡§®‡§æ‡§®‡§æ‡•§</li>',
                    'sec6-elec-title': '‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§î‡§∞ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§ï‡§§‡§æ', 'sec6-elec-list': '<li>‡§¨‡•à‡§†‡§ï‡•ã‡§Ç, ‡§ï‡•â‡§≤‡•ã‡§Ç ‡§î‡§∞ ‡§µ‡•á‡§¨‡§ø‡§®‡§æ‡§∞‡•ã‡§Ç ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§®‡•§</li><li>‡§π‡•à‡§Ç‡§°‡•ç‡§∏-‡§´‡•ç‡§∞‡•Ä ‡§ü‡§æ‡§á‡§™‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•â‡§Ø‡§∏ ‡§®‡•ã‡§ü‡•ç‡§∏ ‡§î‡§∞ ‡§°‡§ø‡§ï‡•ç‡§ü‡•á‡§∂‡§®‡•§</li><li>‡§∏‡•Å‡§®‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Ö‡§ï‡•ç‡§∑‡§Æ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§π‡•Å‡§Ç‡§ö ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞‡•§</li>',
                    'sec6-naic-title': '‡§°‡•á‡§µ‡§≤‡§™‡§∞ ‡§â‡§™‡§ï‡§∞‡§£', 'sec6-naic-list': '<li>‡§Ü‡§µ‡§æ‡§ú-‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§á‡§Ç‡§ü‡§∞‡§´‡•á‡§∏ ‡§î‡§∞ ‡§è‡§™‡•ç‡§≤‡§ø‡§ï‡•á‡§∂‡§® ‡§¨‡§®‡§æ‡§®‡§æ‡•§</li><li>‡§≠‡§æ‡§µ‡§®‡§æ ‡§Ø‡§æ ‡§ï‡•Ä‡§µ‡§∞‡•ç‡§° ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§°‡•á‡§ü‡§æ ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£‡•§</li><li>‡§Ü‡§µ‡§æ‡§ú-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§µ‡§∞‡•ç‡§ö‡•Å‡§Ö‡§≤ ‡§∏‡§π‡§æ‡§Ø‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§ï‡•ç‡§§‡§ø ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡§æ‡•§</li>',
                    'sec7-title': '7. ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§î‡§∞ ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï üéôÔ∏è',
                    'sec7-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•á ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•ã ‡§Ü‡§Æ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§Æ‡§æ‡§®‡§ï ‡§Ö‡§ï‡§æ‡§¶‡§Æ‡§ø‡§ï ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§™‡§∞ ‡§á‡§∏‡§ï‡•Ä ‡§∂‡§¨‡•ç‡§¶ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§¶‡§∞ (WER) ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§Æ‡§æ‡§™‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§ ‡§ï‡§Æ WER ‡§â‡§ö‡•ç‡§ö ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§ï‡•ã ‡§á‡§Ç‡§ó‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§',
                    'sec7-qualities-title': '‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï: ‡§∂‡§¨‡•ç‡§¶ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§¶‡§∞ (WER)',
                    'sec7-qualities-list': '<li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üìä</span><div><strong class="text-white">‡§Ø‡§π ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à:</strong> WER ‡§è‡§è‡§∏‡§Ü‡§∞ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§ï‡•ã ‡§Æ‡§æ‡§™‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó ‡§Æ‡§æ‡§®‡§ï ‡§π‡•à‡•§ ‡§Ø‡§π ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ (‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡•ç‡§•‡§æ‡§™‡§®, ‡§µ‡§ø‡§≤‡•ã‡§™‡§®, ‡§∏‡§Æ‡•ç‡§Æ‡§ø‡§≤‡§®) ‡§ï‡•ã ‡§ï‡•Å‡§≤ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§∏‡•á ‡§µ‡§ø‡§≠‡§æ‡§ú‡§ø‡§§ ‡§ï‡§∞‡§ï‡•á ‡§ó‡§£‡§®‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§</div></li><li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üéØ</span><div><strong class="text-white">‡§Æ‡§ú‡§¨‡•Ç‡§§‡•Ä:</strong> ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡§à ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§™‡§∞ ‡§Ö‡§§‡•ç‡§Ø‡§æ‡§ß‡•Å‡§®‡§ø‡§ï ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§∂‡•ã‡§∞ ‡§µ‡§æ‡§≤‡•á ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§î‡§∞ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§≤‡§π‡§ú‡•á ‡§™‡§∞ ‡§≠‡•Ä ‡§Æ‡§ú‡§¨‡•Ç‡§§ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§¶‡§ø‡§ñ‡§æ‡§§‡§æ ‡§π‡•à ‡§ú‡§π‡§æ‡§Ç ‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§Æ‡•â‡§°‡§≤ ‡§∏‡§Ç‡§ò‡§∞‡•ç‡§∑ ‡§ï‡§∞‡§§‡•á ‡§•‡•á‡•§</div></li><li class="flex items-start"><span class="text-2xl text-[#9f7aea] mr-3">üåç</span><div><strong class="text-white">‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§®:</strong> ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á‡§µ‡§≤ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§π‡•Ä ‡§®‡§π‡•Ä‡§Ç, ‡§¨‡§≤‡•ç‡§ï‡§ø ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•Ä ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ï‡§Æ WER ‡§¶‡§ø‡§ñ‡§æ‡§§‡§æ ‡§π‡•à‡•§</div></li>',
                    'sec8-title': '8. ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§Ö‡§≠‡•ç‡§Ø‡§æ‡§∏ üìà',
                    'sec8-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§∏‡•á ‡§â‡§ö‡•ç‡§ö‡§§‡§Æ ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§µ‡§æ‡§≤‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§Ö‡§™‡§®‡•á ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•Å‡§õ ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§™‡•ç‡§∞‡§•‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§™‡§æ‡§≤‡§® ‡§ï‡§∞‡§®‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§',
                    'sec8-steps-title': 'üìö ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡§ø‡§¶‡•ç‡§ß‡§æ‡§Ç‡§§:',
                    'sec8-step1-title': '‡§â‡§ö‡•ç‡§ö ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§µ‡§æ‡§≤‡§æ ‡§ë‡§°‡§ø‡§Ø‡•ã', 'sec8-step1-desc': '‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§ø‡§§‡§®‡§æ ‡§∏‡§æ‡§´ ‡§π‡•ã‡§ó‡§æ, ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ ‡§â‡§§‡§®‡§æ ‡§π‡•Ä ‡§¨‡•á‡§π‡§§‡§∞ ‡§π‡•ã‡§ó‡§æ‡•§ ‡§è‡§ï ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡§º‡•ã‡§® ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§™‡•É‡§∑‡•ç‡§†‡§≠‡•Ç‡§Æ‡§ø ‡§∂‡•ã‡§∞ ‡§î‡§∞ ‡§ó‡•Ç‡§Ç‡§ú ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§∞‡•á‡§Ç‡•§',
                    'sec8-step2-title': '‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§≠‡§æ‡§∑‡§£', 'sec8-step2-desc': '‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§î‡§∞ ‡§Æ‡§ß‡•ç‡§Ø‡§Æ ‡§ó‡§§‡§ø ‡§∏‡•á ‡§¨‡•ã‡§≤‡•á‡§Ç‡•§ ‡§¨‡§°‡§º‡§¨‡§°‡§º‡§æ‡§®‡•á ‡§Ø‡§æ ‡§¨‡§π‡•Å‡§§ ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§¨‡•ã‡§≤‡§®‡•á ‡§∏‡•á ‡§¨‡§ö‡•á‡§Ç‡•§ ‡§è‡§ï ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§™‡§∞ ‡§¨‡•ã‡§≤‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡§à ‡§µ‡§ï‡•ç‡§§‡§æ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§∞ ‡§¶‡•á‡§Ç‡§ó‡•á‡•§',
                    'sec8-step3-title': '‡§∏‡§π‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç', 'sec8-step3-desc': '‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•á ‡§Æ‡•â‡§°‡§≤ ‡§Ü‡§ï‡§æ‡§∞ (`large-v3`) ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç ‡§ú‡§ø‡§∏‡•á ‡§Ü‡§™‡§ï‡§æ ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§è‡§™‡•Ä‡§Ü‡§à ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§π‡§Æ‡•á‡§∂‡§æ ‡§®‡§µ‡•Ä‡§®‡§§‡§Æ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡•§',
                    'sec8-revision-title': 'üîÑ ‡§è‡§™‡•Ä‡§Ü‡§à ‡§î‡§∞ ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü‡§ø‡§Ç‡§ó:',
                    'sec8-revision-list': '<li><strong>‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç:</strong> ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§®‡§æ‡§Æ‡•ã‡§Ç, ‡§∂‡§¨‡•ç‡§¶‡§ú‡§æ‡§≤ ‡§Ø‡§æ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§£‡•Ä ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§π‡•Ä ‡§µ‡§∞‡•ç‡§§‡§®‡•Ä ‡§ï‡•Ä ‡§è‡§ï ‡§∏‡•Ç‡§ö‡•Ä ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§™‡•Ä‡§Ü‡§à ‡§Æ‡•á‡§Ç `‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü` ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§â‡§®‡§ï‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§π‡•ã ‡§∏‡§ï‡•á‡•§</li><li><strong>‡§≤‡§Ç‡§¨‡•Ä ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§µ‡§ø‡§≠‡§æ‡§ú‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ:</strong> ‡§¨‡§π‡•Å‡§§ ‡§≤‡§Ç‡§¨‡•Ä ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§æ‡§á‡§≤‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§è‡§™‡•Ä‡§Ü‡§à ‡§ï‡•ã ‡§≠‡•á‡§ú‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§õ‡•ã‡§ü‡•á ‡§π‡§ø‡§∏‡•ç‡§∏‡•ã‡§Ç (‡§ú‡•à‡§∏‡•á, 10-15 ‡§Æ‡§ø‡§®‡§ü) ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§æ‡§ú‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à‡•§</li>',
                    'sec9-title': '9. ‡§Æ‡•â‡§°‡§≤ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§î‡§∞ ‡§µ‡§ø‡§ï‡§æ‡§∏ üóìÔ∏è',
                    'sec9-p1': '‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§®‡•á ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§ï‡§à ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§è ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§®‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ, ‡§≠‡§æ‡§∑‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§î‡§∞ ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ ‡§ï‡•á ‡§Æ‡§æ‡§Æ‡§≤‡•á ‡§Æ‡•á‡§Ç ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§',
                    'sec9-step1-title': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ (v1) ‡§∞‡§ø‡§≤‡•Ä‡§ú', 'sec9-step1-desc': '<strong>‡§∏‡§Æ‡§Ø‡§∞‡•á‡§ñ‡§æ:</strong> ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ 2022‡•§ ‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§™‡§π‡§≤‡•á ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§è‡§è‡§∏‡§Ü‡§∞ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§Æ‡§æ‡§®‡§ï ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§',
                    'sec9-step2-title': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§è‡§™‡•Ä‡§Ü‡§à ‡§≤‡•â‡§®‡•ç‡§ö', 'sec9-step2-desc': '<strong>‡§∏‡§Æ‡§Ø‡§∞‡•á‡§ñ‡§æ:</strong> ‡§Æ‡§æ‡§∞‡•ç‡§ö 2023‡•§ ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ `large-v2` ‡§Æ‡•â‡§°‡§≤ ‡§è‡§™‡•Ä‡§Ü‡§à ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§°‡•á‡§µ‡§≤‡§™‡§∞‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§á‡§∏‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡§æ ‡§Ü‡§∏‡§æ‡§® ‡§π‡•ã ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§',
                    'sec9-step3-title': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§≤‡§æ‡§∞‡•ç‡§ú-v3 ‡§∞‡§ø‡§≤‡•Ä‡§ú', 'sec9-step3-desc': '<strong>‡§∏‡§Æ‡§Ø‡§∞‡•á‡§ñ‡§æ:</strong> ‡§®‡§µ‡§Ç‡§¨‡§∞ 2023‡•§ ‡§ï‡§à ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§∏‡§æ‡§• ‡§è‡§ï ‡§Ö‡§¶‡•ç‡§Ø‡§§‡§® ‡§î‡§∞ ‡§¨‡•á‡§π‡§§‡§∞ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§',
                    'sec10-title': '10. ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§®‡•Å‡§ï‡§∏‡§æ‡§® ‡§î‡§∞ ‡§∏‡•Ä‡§Æ‡§æ‡§è‡§Ç üö´',
                    'sec10-p1': '‡§Ö‡§™‡§®‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•á ‡§¨‡§æ‡§µ‡§ú‡•Ç‡§¶, ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§∏‡§π‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§á‡§∏‡§ï‡•Ä ‡§∏‡•Ä‡§Æ‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡•á ‡§∏‡•á ‡§∏‡§π‡•Ä ‡§â‡§Æ‡•ç‡§Æ‡•Ä‡§¶‡•á‡§Ç ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§Æ‡§ø‡§≤‡§§‡•Ä ‡§π‡•à‡•§',
                    'sec10-mistake1-title': '‡§µ‡§ï‡•ç‡§§‡§æ ‡§°‡§æ‡§Ø‡§∞‡§æ‡§á‡§ú‡•á‡§∂‡§®:', 'sec10-mistake1-desc': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§∏‡•ç‡§µ‡§æ‡§≠‡§æ‡§µ‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Ø‡§π ‡§®‡§π‡•Ä‡§Ç ‡§™‡§π‡§ö‡§æ‡§®‡§§‡§æ ‡§ï‡§ø ‡§ï‡•å‡§® ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à (‡§∏‡•ç‡§™‡•Ä‡§ï‡§∞ ‡§°‡§æ‡§Ø‡§∞‡§æ‡§á‡§ú‡•á‡§∂‡§®)‡•§ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§™‡§æ‡§† ‡§ï‡§æ ‡§è‡§ï ‡§π‡•Ä ‡§¨‡•ç‡§≤‡•â‡§ï ‡§π‡•à, ‡§ö‡§æ‡§π‡•á ‡§ï‡§ø‡§§‡§®‡•á ‡§≠‡•Ä ‡§µ‡§ï‡•ç‡§§‡§æ ‡§π‡•ã‡§Ç‡•§',
                    'sec10-mistake2-title': '‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§®:', 'sec10-mistake2-desc': '‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§Æ‡•â‡§°‡§≤ ‡§Ü‡§â‡§ü-‡§ë‡§´-‡§¶-‡§¨‡•â‡§ï‡•ç‡§∏ ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§â‡§ö‡•ç‡§ö ‡§µ‡§ø‡§≤‡§Ç‡§¨‡§§‡§æ ‡§π‡•ã ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§',
                    'sec10-mistake3-title': '‡§Æ‡§§‡§ø‡§≠‡•ç‡§∞‡§Æ ‡§™‡§æ‡§†:', 'sec10-mistake3-desc': '‡§ö‡•Å‡§™ ‡§Ø‡§æ ‡§Ö‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ñ‡§Ç‡§°‡•ã‡§Ç ‡§™‡§∞, ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§≠‡•Ä-‡§ï‡§≠‡•Ä "‡§Æ‡§§‡§ø‡§≠‡•ç‡§∞‡§Æ" ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§¶‡•ã‡§π‡§∞‡§æ‡§µ‡§¶‡§æ‡§∞ ‡§Ø‡§æ ‡§®‡§ø‡§∞‡§∞‡•ç‡§•‡§ï ‡§™‡§æ‡§† ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§',
                    'sec10-mistake4-title': '‡§∂‡§¨‡•ç‡§¶‡§ú‡§æ‡§≤ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∏‡§Ç‡§ò‡§∞‡•ç‡§∑:', 'sec10-mistake4-desc': '‡§Æ‡§ú‡§¨‡•Ç‡§§ ‡§π‡•ã‡§§‡•á ‡§π‡•Å‡§è ‡§≠‡•Ä, ‡§Ø‡§π ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∂‡§¨‡•ç‡§¶‡§ú‡§æ‡§≤, ‡§Ö‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§®‡§æ‡§Æ‡•ã‡§Ç ‡§Ø‡§æ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§£‡•Ä ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§Ø‡§æ‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§ú‡•ã ‡§á‡§∏‡§ï‡•á ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§°‡•á‡§ü‡§æ ‡§Æ‡•á‡§Ç ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§§‡•ç‡§µ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§',
                    'sec11-title': '11. ‡§ï‡•à‡§∏‡•á ‡§™‡§π‡•Å‡§Ç‡§ö‡•á‡§Ç ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç üè´',
                    'sec11-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§ï‡§à ‡§§‡§∞‡•Ä‡§ï‡•á ‡§π‡•à‡§Ç, ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§è‡§™‡•Ä‡§Ü‡§à ‡§ï‡•â‡§≤ ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§Ö‡§™‡§®‡•á ‡§∏‡•ç‡§µ‡§Ø‡§Ç ‡§ï‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ö‡§≤‡§æ‡§®‡•á ‡§§‡§ï‡•§',
                    'sec11-gov-title': 'üìö ‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§è‡§™‡•Ä‡§Ü‡§à ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á', 'sec11-gov-list': '<li>‡§∏‡§¨‡§∏‡•á ‡§Ü‡§∏‡§æ‡§® ‡§î‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Å‡§∂‡§≤ ‡§§‡§∞‡•Ä‡§ï‡§æ‡•§ ‡§¨‡§∏ ‡§è‡§ï ‡§è‡§™‡•Ä‡§Ü‡§à ‡§ï‡•Å‡§Ç‡§ú‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§æ‡§á‡§® ‡§Ö‡§™ ‡§ï‡§∞‡•á‡§Ç‡•§</li><li>‡§è‡§™‡•Ä‡§Ü‡§à ‡§è‡§Ç‡§°‡§™‡•â‡§á‡§Ç‡§ü ‡§™‡§∞ ‡§è‡§ï ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§º‡§æ‡§á‡§≤ ‡§≠‡•á‡§ú‡•á‡§Ç ‡§î‡§∞ ‡§™‡§æ‡§† ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ ‡§µ‡§æ‡§™‡§∏ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§</li><li>‡§ú‡§ü‡§ø‡§≤ ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§Ø‡§æ ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§®‡§ø‡§∞‡•ç‡§≠‡§∞‡§§‡§æ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§</li>',
                    'sec11-pvt-title': 'üíª ‡§ì‡§™‡§® ‡§∏‡•ã‡§∞‡•ç‡§∏', 'sec11-pvt-p1': '‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡§§‡§æ ‡§µ‡§æ‡§≤‡•á ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è‡•§', 'sec11-pvt-list': '<li>‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§ì‡§™‡§®‡§è‡§Ü‡§à ‡§ó‡§ø‡§ü‡§π‡§¨ ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä ‡§∏‡•á ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§ï‡•ã‡§° ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç‡•§</li><li>‡§â‡§ö‡§ø‡§§ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§ú‡•Ä‡§™‡•Ä‡§Ø‡•Ç (‡§ú‡•à‡§∏‡•á ‡§è‡§®‡§µ‡•Ä‡§Ü‡§à‡§°‡•Ä‡§Ü‡§à‡§è) ‡§ï‡•á ‡§∏‡§æ‡§• ‡§è‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§∞ ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•à‡•§</li><li>‡§Ü‡§™‡§ï‡•ã ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§á‡§∏‡§ï‡•á ‡§â‡§™‡§Ø‡•ã‡§ó ‡§™‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§</li>',
                    'sec12-title': '12. ‡§µ‡§æ‡§ï‡•ç ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡§æ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø üöÄ',
                    'sec12-p1': '‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§®‡•á ‡§è‡§è‡§∏‡§Ü‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§®‡§à ‡§Ü‡§ß‡§æ‡§∞ ‡§∞‡•á‡§ñ‡§æ ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡•Ä ‡§π‡•à‡•§ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§≠‡•Ä ‡§â‡§®‡•ç‡§®‡§§ ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Ç ‡§¶‡•á‡§ñ‡§®‡•á ‡§ï‡•ã ‡§Æ‡§ø‡§≤‡•á‡§Ç‡§ó‡•Ä, ‡§ú‡•ã ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§® ‡§∏‡•á ‡§™‡§∞‡•á ‡§¨‡•ã‡§≤‡•Ä ‡§ú‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§∏‡§Ç‡§ö‡§æ‡§∞ ‡§ï‡•Ä ‡§ó‡§π‡§∞‡•Ä ‡§∏‡§Æ‡§ù ‡§§‡§ï ‡§ú‡§æ‡§è‡§Ç‡§ó‡•Ä‡•§',
                    'sec12-career-btn': '‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§ø‡§§ ‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§¶‡•á‡§ñ‡•á‡§Ç',
                    'sec13-title': '13. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§è‡§è‡§∏‡§Ü‡§∞ ‡§Ö‡§µ‡§ß‡§æ‡§∞‡§£‡§æ‡§è‡§Ç üìö',
                    'sec13-p1': '‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§µ‡§æ‡§ï‡•ç ‡§™‡§π‡§ö‡§æ‡§® (‡§è‡§è‡§∏‡§Ü‡§∞) ‡§ï‡•Ä ‡§á‡§® ‡§Æ‡•Ç‡§≤‡§≠‡•Ç‡§§ ‡§Ö‡§µ‡§ß‡§æ‡§∞‡§£‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡§æ ‡§µ‡•ç‡§π‡§ø‡§∏‡•ç‡§™‡§∞ ‡§ï‡•á ‡§™‡•Ä‡§õ‡•á ‡§ï‡•Ä ‡§§‡§ï‡§®‡•Ä‡§ï ‡§ï‡•Ä ‡§∏‡§∞‡§æ‡§π‡§®‡§æ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§',
                    'syllabus-oir-title': '‡§Æ‡•Ç‡§≤‡§≠‡•Ç‡§§ ‡§µ‡§ø‡§ö‡§æ‡§∞',
                    'syllabus-oir-list': '<div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üîä</span><div class="flex-grow">‡§´‡•ã‡§®‡§Æ‡•á‡§∏ ‡§î‡§∞ ‡§∏‡•ç‡§™‡•á‡§ï‡•ç‡§ü‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">‡§®‡•ã‡§ü‡•ç‡§∏</button><button class="lectures-btn">‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§®</button></div></div><div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üìä</span><div class="flex-grow">‡§∂‡§¨‡•ç‡§¶ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§¶‡§∞ (WER)</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">‡§®‡•ã‡§ü‡•ç‡§∏</button><button class="lectures-btn">‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§®</button></div></div>',
                    'syllabus-ppdt-title': '‡§∏‡•ç‡§•‡§æ‡§™‡§§‡•ç‡§Ø ‡§ò‡§ü‡§ï',
                    'syllabus-ppdt-list': '<div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">‚û°Ô∏è</span><div class="flex-grow">‡§è‡§®‡§ï‡•ã‡§°‡§∞-‡§°‡§ø‡§ï‡•ã‡§°‡§∞ ‡§Æ‡•â‡§°‡§≤</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">‡§®‡•ã‡§ü‡•ç‡§∏</button><button class="lectures-btn">‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§®</button></div></div><div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üß†</span><div class="flex-grow">‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§´‡§æ‡§∞‡•ç‡§Æ‡§∞ ‡§î‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§®</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">‡§®‡•ã‡§ü‡•ç‡§∏</button><button class="lectures-btn">‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§®</button></div></div>',
                    'footer-text': '&copy; 2025 | ‡§≠‡§æ‡§∑‡§£ ‡§ï‡§æ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§Ø‡§π‡§æ‡§Å ‡§π‡•à‡•§',
                    'interviewChartData': {
                        labels: ['‡§∏‡§æ‡§´ ‡§ë‡§°‡§ø‡§Ø‡•ã', '‡§∂‡•ã‡§∞‡§ó‡•Å‡§≤ ‡§µ‡§æ‡§≤‡§æ ‡§ë‡§°‡§ø‡§Ø‡•ã', '‡§µ‡§ø‡§¶‡•á‡§∂‡•Ä ‡§≤‡§π‡§ú‡§æ', '‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶'],
                        data: [98, 92, 90, 95] 
                    }
                }
            };
            
            function renderPostCards(lang) {
                const container = document.getElementById('postCardsContainer');
                if (!container) return;
                container.innerHTML = '';
                const posts = serviceDetailsData[lang];
                for (const id in posts) {
                    const post = posts[id];
                    const card = document.createElement('div');
                    card.className = 'group relative p-6 bg-[#2a2b3a]/50 rounded-xl text-center border-2 border-slate-700 hover:border-teal-400 transition-all duration-300 cursor-pointer shadow-lg hover:shadow-2xl transform hover:-translate-y-2';
                    card.dataset.postId = id;
                    card.innerHTML = `
                        <div class="text-6xl mb-4 transition-transform duration-300 group-hover:scale-110">${post.icon}</div>
                        <h4 class="font-bold text-xl text-white">${post.name}</h4>
                        <p class="text-sm text-indigo-200 mt-2">${post.cta}</p>
                        <div class="absolute top-3 right-3 text-teal-400 opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M7 17l9.2-9.2M17 17V7H7"/></svg>
                        </div>
                    `;
                    card.addEventListener('click', () => showPostDetails(id));
                    container.appendChild(card);
                }
            }

            function showPostDetails(postId) {
                const post = serviceDetailsData[currentLang][postId];
                if (post) {
                    document.getElementById('postDetailIcon').innerText = post.icon;
                    document.getElementById('postDetailTitle').innerText = post.name;
                    document.getElementById('postDetailDescription').innerText = post.description;
                    showModal('postDetailModal');
                }
            }

            function renderCareerPath(lang) {
                const container = document.getElementById('careerPathContainer');
                container.innerHTML = '';
                const path = careerPathData[lang].path;
                path.forEach((step) => {
                    const stepElement = document.createElement('div');
                    stepElement.className = 'timeline-step';
                    stepElement.innerHTML = `
                        <div class="timeline-dot"></div>
                        <h4 class="font-semibold text-xl text-white mb-1">${step.rank}</h4>
                        <p class="text-base text-indigo-200">${step.desc}</p>
                    `;
                    container.appendChild(stepElement);
                });
            }

            function initInterviewChart() {
                const ctx = document.getElementById('interviewQualitiesChart').getContext('2d');
                interviewChartInstance = new Chart(ctx, {
                    type: 'bar',
                    data: {
                        labels: translations.en.interviewChartData.labels,
                        datasets: [{
                            label: 'Accuracy (%)',
                            data: translations.en.interviewChartData.data,
                            backgroundColor: 'rgba(0, 240, 181, 0.7)',
                            borderColor: '#00f0b5',
                            borderWidth: 2,
                            borderRadius: 8,
                        }]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        plugins: { legend: { display: false } },
                        scales: {
                            y: { 
                                beginAtZero: true, 
                                max: 100,
                                ticks: { color: '#e0e0e0' },
                                grid: { color: 'rgba(224, 224, 224, 0.1)' }
                            },
                            x: { 
                                ticks: { color: '#e0e0e0', font: { size: 14 } },
                                grid: { color: 'rgba(224, 224, 224, 0.0)' }
                            }
                        }
                    }
                });
            }

            function translateChart() {
                if (interviewChartInstance) {
                    const data = translations[currentLang].interviewChartData;
                    interviewChartInstance.data.labels = data.labels;
                    interviewChartInstance.data.datasets[0].data = data.data;
                    interviewChartInstance.update();
                }
            }
            
            function translatePage(lang) {
                currentLang = lang;
                document.documentElement.lang = lang;
                for (const id in translations[lang]) {
                    const element = document.getElementById(id);
                    if (element) {
                        element.innerHTML = translations[lang][id];
                    }
                }
                renderPostCards(lang);
                renderCareerPath(lang);
                translateChart();
            }

            document.querySelectorAll('.lang-btn').forEach(button => {
                button.addEventListener('click', (e) => {
                    document.querySelectorAll('.lang-btn').forEach(btn => btn.classList.remove('active'));
                    e.currentTarget.classList.add('active');
                    translatePage(e.currentTarget.dataset.lang);
                });
            });

            const showModal = (modalId) => document.getElementById(modalId)?.classList.add('active');
            const closeModal = (modal) => modal?.classList.remove('active');

            document.querySelectorAll('[data-modal-target]').forEach(trigger => {
                trigger.addEventListener('click', () => showModal(trigger.dataset.modalTarget));
            });


            document.querySelectorAll('.modal-overlay').forEach(modal => {
                modal.addEventListener('click', (e) => {
                    if (e.target === modal) closeModal(modal);
                });
                modal.querySelector('.modal-close-button')?.addEventListener('click', () => closeModal(modal));
            });
            
            // Initial render
            initInterviewChart();
            translatePage('en');
        });
    </script>
</body>
</html>

