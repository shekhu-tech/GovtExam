<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mistral Mixtral: The Ultimate Guide</title>
    <script src="redirect_if_needed.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700;800&display=swap" rel="stylesheet">
    <meta name="description" content="A complete guide to Mistral's Mixtral models. Understand its Sparse Mixture-of-Experts (SMoE) architecture, its open-source nature, capabilities, and applications.">
    <meta name="keywords" content="Mistral, Mixtral, Mixtral 8x7B, Open Source AI, Large Language Models, AI, Mixture of Experts, SMoE, Generative AI">
    <meta name="author" content="AI Tools Guide">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #1a1a1a; /* Deep Charcoal */
            color: #f0f0f0; /* Light Gray */
        }
        .section-heading {
            border-image: linear-gradient(to right, #ff6700, #00a9e0) 1;
            border-bottom: 4px solid;
            padding-bottom: 0.5rem;
            margin-bottom: 1.5rem;
            display: inline-block;
            color: #ffffff; /* White */
        }
        .card {
            background: rgba(26, 26, 26, 0.8); /* Dark Charcoal Transparent */
            backdrop-filter: blur(16px);
            -webkit-backdrop-filter: blur(16px);
            border-radius: 1.25rem;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.5);
            padding: 2rem;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            border: 1px solid #444444; /* Medium Gray */
        }
        .card:hover {
            box-shadow: 0 0 40px rgba(255, 103, 0, 0.2);
            transform: translateY(-12px) scale(1.02);
            border-color: #ff6700; /* Molten Orange */
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 550px;
            margin: auto;
            height: 320px;
            max-height: 450px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 380px;
            }
        }
        .flowchart-step {
            border: 3px solid #ff6700; /* Molten Orange */
            color: #ff6700;
            background: #2a2a2a; /* Dark Gray */
            transition: all 0.3s ease-in-out;
            cursor: pointer;
            box-shadow: 0 0 15px rgba(255, 103, 0, 0.2);
            text-shadow: 0 1px 2px rgba(0,0,0,0.5);
        }
        .flowchart-step:hover {
            background-color: #ff6700;
            color: #1a1a1a;
            transform: scale(1.08);
            box-shadow: 0 0 25px rgba(255, 103, 0, 0.5);
        }
        .flowchart-arrow {
            color: #00a9e0; /* Steel Blue */
            text-shadow: 0 0 10px rgba(0, 169, 224, 0.5);
        }
        .subject-category-heading {
            color: #ffffff;
            font-weight: 700;
            margin-bottom: 1rem;
            font-size: 1.3rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #00a9e0;
        }
        .subject-item {
            display: flex;
            align-items: center;
            margin-bottom: 0.75rem;
            padding: 0.75rem;
            border-radius: 0.75rem;
            transition: background-color 0.2s;
        }
        .subject-item:hover {
            background-color: rgba(0, 169, 224, 0.1);
        }
        .subject-item .icon {
            color: #00a9e0;
            margin-right: 1rem;
            font-size: 1.5rem;
        }
        .timeline-step {
            position: relative;
            padding-left: 2.5rem;
            padding-bottom: 2.5rem;
            border-left: 4px solid #ff6700;
        }
        .timeline-step:last-child {
            padding-bottom: 0;
        }
        .timeline-dot {
            position: absolute;
            left: -0.9375rem;
            top: 0;
            width: 1.75rem;
            height: 1.75rem;
            border-radius: 50%;
            background-color: #1a1a1a;
            border: 4px solid #ff6700;
            box-shadow: 0 0 15px rgba(255, 103, 0, 0.7);
        }
        .modal-overlay {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background-color: rgba(26, 26, 26, 0.85);
            backdrop-filter: blur(8px);
            -webkit-backdrop-filter: blur(8px);
            display: flex;
            align-items: center; justify-content: center;
            z-index: 1000;
            opacity: 0; visibility: hidden;
            transition: opacity 0.3s ease, visibility 0.3s ease;
            padding: 1rem;
        }
        .modal-overlay.active {
            opacity: 1; visibility: visible;
        }
        .modal-content {
            background-color: #2a2a2a;
            color: #f0f0f0;
            border-radius: 1rem;
            padding: 2.5rem;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.5);
            max-width: 800px;
            width: 100%;
            position: relative;
            transform: translateY(20px) scale(0.98);
            opacity: 0;
            transition: transform 0.4s ease, opacity 0.4s ease;
            max-height: 90vh;
            overflow-y: auto;
            border: 1px solid #444444;
        }
        .modal-overlay.active .modal-content {
            transform: translateY(0) scale(1);
            opacity: 1;
        }
        .modal-close-button {
            position: absolute; top: 1rem; right: 1rem;
            background: none; border: none; font-size: 2.5rem;
            cursor: pointer; color: #a3a3a3; line-height: 1;
            transition: color 0.2s, transform 0.2s;
        }
        .modal-close-button:hover { color: #f87171; transform: rotate(90deg); }
        .modal-action-button {
            background: linear-gradient(45deg, #ff6700, #f97316);
            color: #ffffff;
            padding: 0.85rem 1.75rem;
            border-radius: 0.75rem;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.3s ease;
            border: none;
            box-shadow: 0 5px 15px rgba(255, 103, 0, 0.3);
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        .modal-action-button:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(255, 103, 0, 0.4);
        }
        .lang-btn {
            padding: 0.6rem 2rem;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.3s;
            border: 2px solid #ff6700;
            color: #ff6700;
            background-color: transparent;
        }
        .lang-btn:first-child { border-top-left-radius: 0.75rem; border-bottom-left-radius: 0.75rem; }
        .lang-btn:last-child { border-top-right-radius: 0.75rem; border-bottom-right-radius: 0.75rem; }
        .lang-btn.active, .lang-btn:hover {
            background-color: #ff6700;
            color: #1a1a1a;
            box-shadow: 0 0 15px #ff6700;
        }
        .notes-btn, .lectures-btn {
            padding: 0.35rem 1rem;
            border-radius: 0.5rem;
            font-size: 0.875rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s ease-in-out;
            border: 1px solid transparent;
            text-transform: uppercase;
        }
        .notes-btn {
            background: linear-gradient(45deg, #00a9e0, #008cba);
            color: #ffffff;
        }
        .notes-btn:hover {
            filter: brightness(1.2);
        }
        .lectures-btn {
            background-color: #444444; 
            color: #f0f0f0; 
            border-color: #555555; 
        }
        .lectures-btn:hover {
            background-color: #555555;
            color: #ffffff;
        }
    </style>
</head>
<body class="leading-relaxed">

    <div class="container mx-auto p-4 sm:p-6 md:p-12">

        <header class="text-center mb-10">
            <h1 id="header-title" class="text-4xl md:text-5xl font-extrabold text-[#ffffff] mb-4 tracking-tight">‚ìÇÔ∏è Mistral Mixtral: The Ultimate Guide ‚ìÇÔ∏è</h1>
            <p id="header-subtitle" class="text-xl md:text-2xl font-semibold bg-clip-text text-transparent bg-gradient-to-r from-orange-400 to-sky-400">Understanding the Power of Sparse Mixture-of-Experts</p>
        </header>

        <div class="text-center mb-12">
            <div class="inline-flex rounded-md shadow-sm" role="group">
                <button type="button" class="lang-btn active" data-lang="en">English</button>
                <button type="button" class="lang-btn" data-lang="hi">‡§π‡§ø‡§Ç‡§¶‡•Ä</button>
            </div>
        </div>

        <main class="grid grid-cols-1 gap-12">

            <!-- Section 1: What is Mixtral? -->
            <section class="card !p-0 overflow-hidden bg-gradient-to-br from-[#2a2a2a] via-[#1a1a1a] to-[#1a1a1a]">
                <div class="p-8">
                    <h2 id="sec1-title" class="text-3xl font-bold section-heading">1. What is Mistral's Mixtral? üí°</h2>
                    <p id="sec1-p1" class="text-lg mb-6">Mixtral 8x7B, developed by the French AI company Mistral AI, is a high-quality sparse mixture-of-experts (SMoE) language model. It's a powerful open-source model that matches or outperforms much larger models like GPT-3.5 on many benchmarks. Its key innovation is the SMoE architecture, which allows it to have a large number of parameters (46.7B total) but only use a fraction of them for any given token, making it incredibly fast and cost-effective for inference.</p>
                </div>
                <div id="postCardsContainer" class="px-8 pb-8 pt-2 grid grid-cols-1 md:grid-cols-3 gap-8 bg-transparent">
                    <!-- Cards will be dynamically inserted here by JavaScript -->
                </div>
            </section>

            <!-- Section 2: How It Works -->
            <section class="card">
                <h2 id="sec2-title" class="text-3xl font-bold section-heading text-center w-full">2. The Mixture-of-Experts (MoE) Architecture üéØ</h2>
                <p id="sec2-p1" class="text-lg text-center mb-10 max-w-3xl mx-auto">Instead of one giant model processing everything, Mixtral uses a "router" to direct each part of a query to specialized "expert" sub-networks, combining their outputs for a final answer.</p>
                <div class="flex flex-col md:flex-row items-center justify-center space-y-8 md:space-y-0 md:space-x-8 lg:space-x-16">
                    <div class="text-center flex flex-col items-center">
                        <div class="w-40 h-40 flex items-center justify-center rounded-full flowchart-step font-bold text-lg p-3 text-center leading-tight" data-modal-target="prelimsMainModal"><span id="sec2-step1-title">Input</span><br><span id="sec2-step1-name">Token Sequence</span></div>
                        <p id="sec2-step1-desc" class="mt-4 font-semibold text-gray-400">User's prompt is tokenized</p>
                    </div>
                    <div class="text-5xl font-light flowchart-arrow transform md:rotate-0 rotate-90">‚Üí</div>
                    <div class="text-center flex flex-col items-center">
                        <div class="w-40 h-40 flex items-center justify-center rounded-full flowchart-step font-bold text-lg p-3 text-center leading-tight" data-modal-target="mainsMainModal"><span id="sec2-step2-title">Router</span><br><span id="sec2-step2-name">Selects Experts</span></div>
                        <p id="sec2-step2-desc" class="mt-4 font-semibold text-gray-400">Router selects 2 of 8 experts for each token</p>
                    </div>
                    <div class="text-5xl font-light flowchart-arrow transform md:rotate-0 rotate-90">‚Üí</div>
                    <div class="text-center flex flex-col items-center">
                        <div class="w-40 h-40 flex items-center justify-center rounded-full flowchart-step font-bold text-lg p-3 text-center leading-tight" data-modal-target="interviewModal"><span id="sec2-step3-title">Output</span><br><span id="sec2-step3-name">Combined Result</span></div>
                        <p id="sec2-step3-desc" class="mt-4 font-semibold text-gray-400">Outputs of the experts are combined</p>
                    </div>
                </div>
            </section>

            <!-- Section 3: Access & Availability -->
            <section class="card">
                <h2 id="sec3-title" class="text-3xl font-bold section-heading">3. Who Can Use It? ‚úÖ</h2>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 items-start">
                    <div>
                        <p id="sec3-p1" class="text-lg mb-6">Mixtral is released under the permissive Apache 2.0 license, making it fully open for a wide array of users.</p>
                        <ul class="space-y-5 text-base">
                            <li class="flex items-start"><span class="text-3xl text-[#0062E0] mr-4">üåê</span><div><strong id="sec3-age-title" class="text-white text-lg">Open Source Community:</strong> <span id="sec3-age-desc">Researchers, hobbyists, and developers can freely download, modify, and build upon the model.</span></div></li>
                            <li class="flex items-start"><span class="text-3xl text-[#0062E0] mr-4">üíº</span><div><strong id="sec3-edu-title" class="text-white text-lg">Businesses & Startups:</strong> <span id="sec3-edu-desc">Companies can use Mixtral to build commercial applications and services without paying licensing fees.</span></div></li>
                        </ul>
                    </div>
                    <div>
                        <h3 id="sec3-attempts-title" class="text-2xl font-bold text-white mb-4 border-b border-[#FFC700] pb-2">Primary Platforms üìä</h3>
                         <ul id="sec3-agerelax-list" class="list-disc list-inside space-y-3 text-base">
                             <li><strong>Hugging Face:</strong> The easiest way to access the models is through the Hugging Face Hub.</li>
                             <li><strong>Cloud Providers:</strong> Available for deployment on major cloud platforms like AWS, Google Cloud, and Azure.</li>
                             <li><strong>Local Inference:</strong> Can be run on local machines with sufficient GPU memory, using tools like Ollama or LM Studio.</li>
                        </ul>
                    </div>
                </div>
            </section>
            
            <!-- Section 4: Core Capabilities -->
            <section class="card bg-black/20">
                <h2 id="sec4-title" class="text-3xl font-bold section-heading text-center w-full">4. Core Capabilities üìö</h2>
                <p id="sec4-p1" class="text-lg text-center mb-10 max-w-4xl mx-auto">Mixtral is a highly proficient language model that excels in multiple domains thanks to its specialized experts.</p>
                 <div id="syllabus-grid" class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8">
                    <div class="bg-[#2a2a2a]/80 backdrop-blur-sm p-6 rounded-xl shadow-lg border border-neutral-700 flex flex-col transition duration-300 hover:shadow-2xl hover:border-blue-500 hover:-translate-y-1">
                        <h3 id="gs1-title" class="subject-category-heading">Code Generation</h3>
                        <p class="text-sm">Strong performance on coding benchmarks, outperforming larger models like CodeLlama 70B.</p>
                    </div>
                     <div class="bg-[#2a2a2a]/80 backdrop-blur-sm p-6 rounded-xl shadow-lg border border-neutral-700 flex flex-col transition duration-300 hover:shadow-2xl hover:border-blue-500 hover:-translate-y-1">
                        <h3 id="gs2-title" class="subject-category-heading">Multilingual</h3>
                         <p class="text-sm">Fluently handles English, French, Italian, German, and Spanish.</p>
                    </div>
                    <div class="bg-[#2a2a2a]/80 backdrop-blur-sm p-6 rounded-xl shadow-lg border border-neutral-700 flex flex-col transition duration-300 hover:shadow-2xl hover:border-blue-500 hover:-translate-y-1">
                        <h3 id="gs3-title" class="subject-category-heading">Long Context</h3>
                         <p class="text-sm">Handles a context of 32,000 tokens, allowing it to process and recall information from long documents.</p>
                    </div>
                    <div class="bg-[#2a2a2a]/80 backdrop-blur-sm p-6 rounded-xl shadow-lg border border-neutral-700 flex flex-col transition duration-300 hover:shadow-2xl hover:border-blue-500 hover:-translate-y-1">
                        <h3 id="gs4-title" class="subject-category-heading">Instruction Following</h3>
                         <p class="text-sm">Excellent at following complex instructions and constraints given in a prompt.</p>
                    </div>
                </div>
            </section>

            <!-- Section 5: Training & Data -->
            <section class="card">
                <h2 id="sec5-title" class="text-3xl font-bold section-heading">5. How was Mixtral Trained? üèõÔ∏è</h2>
                <p id="sec5-p1" class="text-lg text-center mb-8 max-w-3xl mx-auto">Mixtral was trained on a vast dataset sourced from the open web and fine-tuned for instruction following.</p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 text-base">
                    <div class="p-6 bg-[#2a2a2a] rounded-xl border-2 border-[#0062E0]">
                        <h3 id="sec5-hindi-title" class="font-bold text-xl text-white mb-2">1. Pre-training</h3>
                        <p id="sec5-hindi-p1" class="text-sm mb-2">The model was trained on a diverse dataset of text and code from the public internet, allowing each of the 8 experts to develop specialized knowledge.</p>
                    </div>
                    <div class="p-6 bg-[#2a2a2a] rounded-xl border-2 border-[#FFC700]">
                        <h3 id="sec5-essay-title" class="font-bold text-xl text-white mb-2">2. Fine-Tuning</h3>
                        <p id="sec5-essay-p1" class="text-sm mb-2">The pretrained base model was then fine-tuned using a combination of Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) to create a helpful, instruction-following chat model.</p>
                    </div>
                </div>
            </section>
            
            <!-- Section 6: Key Applications -->
            <section class="card">
                <h2 id="sec6-title" class="text-3xl font-bold section-heading">6. Key Applications & Use Cases üåü</h2>
                <p id="sec6-p1" class="text-lg text-center mb-8 max-w-4xl mx-auto">Mixtral's blend of high performance and efficiency makes it ideal for a wide range of real-world applications.</p>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-8 text-base">
                    <div>
                        <h3 id="sec6-eng-title" class="subject-category-heading">Enterprise Chatbots</h3>
                        <ul id="sec6-eng-list" class="list-disc list-inside space-y-2 text-base">
                           <li>Building powerful internal and external chatbots.</li>
                           <li>Retrieval-Augmented Generation (RAG) on company documents.</li>
                        </ul>
                    </div>
                    <div>
                        <h3 id="sec6-elec-title" class="subject-category-heading">Software Development</h3>
                        <ul id="sec6-elec-list" class="list-disc list-inside space-y-2 text-base">
                           <li>High-performance code completion.</li>
                           <li>Generating and debugging complex code.</li>
                           <li>Powering developer assistant tools.</li>
                        </ul>
                    </div>
                     <div>
                        <h3 id="sec6-naic-title" class="subject-category-heading">Content & Analysis</h3>
                        <ul id="sec6-naic-list" class="list-disc list-inside space-y-2 text-base">
                           <li>Summarizing long reports and articles.</li>
                           <li>Drafting emails, marketing copy, and creative text.</li>
                           <li>Classifying and analyzing text data at scale.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Section 7: Performance Benchmarks -->
            <section class="card grid grid-cols-1 lg:grid-cols-2 gap-8 items-center">
                <div>
                     <h2 id="sec7-title" class="text-3xl font-bold section-heading">7. Performance & Benchmarks üéôÔ∏è</h2>
                    <p id="sec7-p1" class="text-lg mb-6">Mixtral 8x7B has demonstrated exceptional performance, matching or outperforming much larger, dense models like Llama 2 70B and GPT-3.5 across a wide array of standard benchmarks.</p>
                    <div class="chart-container h-80">
                        <canvas id="interviewQualitiesChart"></canvas>
                    </div>
                </div>
                <div>
                    <h3 id="sec7-qualities-title" class="text-2xl font-bold text-white mb-6 border-b border-[#0062E0] pb-2">Key Benchmarks:</h3>
                    <ul id="sec7-qualities-list" class="space-y-4 text-base">
                        <li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üß†</span><div><strong class="text-white">MMLU (Reasoning):</strong> Outperforms Llama 2 70B, showcasing its strong general knowledge and reasoning abilities.</div></li>
                        <li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üíª</span><div><strong class="text-white">HumanEval (Coding):</strong> Significantly outperforms larger models, establishing it as a top-tier open-source code generation model.</div></li>
                        <li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üî¢</span><div><strong class="text-white">GSM8K (Math):</strong> Achieves a very high score on grade-school math problems, demonstrating strong mathematical reasoning.</div></li>
                    </ul>
                </div>
            </section>
            
            <!-- Section 8: Prompt Engineering -->
            <section class="card">
                <h2 id="sec8-title" class="text-3xl font-bold section-heading">8. Prompting Mixtral: Best Practices üìà</h2>
                <p id="sec8-p1" class="text-lg mb-8 max-w-4xl mx-auto">To get the best performance from the Mixtral-Instruct model, it's important to follow the specific chat template it was trained on.</p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div>
                        <h3 id="sec8-steps-title" class="text-2xl font-bold text-white mb-4">üìö The Chat Template:</h3>
                        <ol class="relative border-l-4 border-[#0062E0] pl-6 space-y-8">
                            <li class="ml-4">
                                <div class="absolute w-4 h-4 bg-[#0062E0] rounded-full -left-2.5 border-4 border-[#2a2a2a]"></div>
                                <h4 id="sec8-step1-title" class="font-semibold text-xl text-white mb-1">Use Instruction Tags</h4>
                                <p id="sec8-step1-desc" class="text-base">Wrap your prompts inside `[INST]` and `[/INST]` tags. For example: `[INST] What is the capital of France? [/INST]`.</p>
                            </li>
                             <li class="ml-4">
                               <div class="absolute w-4 h-4 bg-[#0062E0] rounded-full -left-2.5 border-4 border-[#2a2a2a]"></div>
                                <h4 id="sec8-step2-title" class="font-semibold text-xl text-white mb-1">Conversational Turns</h4>
                                <p id="sec8-step2-desc" class="text-base">For a multi-turn conversation, you can chain prompts and responses together, ensuring each user prompt is correctly tagged.</p>
                            </li>
                        </ol>
                    </div>
                    <div>
                        <h3 id="sec8-revision-title" class="text-2xl font-bold text-white mb-4">üîÑ General Tips:</h3>
                         <ul id="sec8-revision-list" class="list-disc list-inside space-y-3 text-base">
                            <li><strong>Be Clear and Concise:</strong> Provide clear and direct instructions for the best results.</li>
                            <li><strong>Provide Context:</strong> For more complex tasks, include relevant context or examples within your prompt.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Section 9: Model Evolution -->
            <section class="card">
                <h2 id="sec9-title" class="text-3xl font-bold section-heading">9. Model Evolution üóìÔ∏è</h2>
                <p id="sec9-p1" class="text-lg mb-8">The Mixtral series represents a significant architectural evolution in Mistral AI's family of open-source models.</p>
                <div class="career-path-timeline">
                    <div class="timeline-step">
                        <div class="timeline-dot"></div>
                        <h4 id="sec9-step1-title" class="font-semibold text-xl text-white mb-1">Mistral 7B</h4>
                        <p id="sec9-step1-desc" class="text-base"><strong class="text-gray-400">Timeline:</strong> September 2023. Mistral's first model, which outperformed much larger models like Llama 2 13B.</p>
                    </div>
                    <div class="timeline-step">
                        <div class="timeline-dot"></div>
                        <h4 id="sec9-step2-title" class="font-semibold text-xl text-white mb-1">Mixtral 8x7B</h4>
                        <p id="sec9-step2-desc" class="text-base"><strong class="text-gray-400">Timeline:</strong> December 2023. The release of the first high-quality, open-source Sparse Mixture-of-Experts model, changing the landscape of efficient AI.</p>
                    </div>
                     <div class="timeline-step">
                        <div class="timeline-dot"></div>
                        <h4 id="sec9-step3-title" class="font-semibold text-xl text-white mb-1">Mixtral 8x22B</h4>
                        <p id="sec9-step3-desc" class="text-base"><strong class="text-gray-400">Timeline:</strong> April 2024. A new, even larger and more capable MoE model released with an open-but-not-commercial license, pushing performance even further.</p>
                    </div>
                </div>
            </section>

            <!-- Section 10: Mistakes -->
            <section class="card">
                <h2 id="sec10-title" class="text-3xl font-bold section-heading text-center w-full">10. Limitations & Considerations üö´</h2>
                <p id="sec10-p1" class="text-lg text-center mb-10 max-w-4xl mx-auto">While Mixtral is highly capable, it is important to be aware of the general limitations of current LLMs.</p>
                <div id="sec10-donts-grid" class="grid grid-cols-1 md:grid-cols-2 gap-8 text-base">
                    <div class="group relative p-6 bg-slate-900/50 rounded-lg border-2 border-red-700 shadow-md transition-all duration-300 hover:shadow-xl hover:border-red-500 hover:-translate-y-1">
                        <div class="absolute -top-4 -left-4 bg-red-600 text-white rounded-full w-12 h-12 flex items-center justify-center text-2xl font-bold shadow-lg group-hover:scale-110 transition-transform">‚ùå</div>
                        <div class="ml-10">
                            <strong id="sec10-mistake1-title" class="text-lg text-red-300">Factual Accuracy:</strong>
                            <p id="sec10-mistake1-desc" class="text-red-400 mt-1">Like all LLMs, Mixtral can "hallucinate" and produce incorrect information. It should not be relied upon for factually critical applications without verification.</p>
                        </div>
                    </div>
                    <div class="group relative p-6 bg-slate-900/50 rounded-lg border-2 border-red-700 shadow-md transition-all duration-300 hover:shadow-xl hover:border-red-500 hover:-translate-y-1">
                         <div class="absolute -top-4 -left-4 bg-red-600 text-white rounded-full w-12 h-12 flex items-center justify-center text-2xl font-bold shadow-lg group-hover:scale-110 transition-transform">‚ùå</div>
                        <div class="ml-10">
                            <strong id="sec10-mistake2-title" class="text-lg text-red-300">Potential for Bias:</strong>
                            <p id="sec10-mistake2-desc" class="text-red-400 mt-1">The model is trained on web data and may reflect the biases present in that data. Careful implementation and guardrails are needed.</p>
                        </div>
                    </div>
                     <div class="group relative p-6 bg-slate-900/50 rounded-lg border-2 border-red-700 shadow-md transition-all duration-300 hover:shadow-xl hover:border-red-500 hover:-translate-y-1">
                         <div class="absolute -top-4 -left-4 bg-red-600 text-white rounded-full w-12 h-12 flex items-center justify-center text-2xl font-bold shadow-lg group-hover:scale-110 transition-transform">‚ùå</div>
                        <div class="ml-10">
                            <strong id="sec10-mistake3-title" class="text-lg text-red-300">No Inherent Safety Filter:</strong>
                            <p id="sec10-mistake3-desc" class="text-red-400 mt-1">The base Mixtral model is not moderated. Developers building applications must implement their own safety and moderation layers.</p>
                        </div>
                    </div>
                     <div class="group relative p-6 bg-slate-900/50 rounded-lg border-2 border-red-700 shadow-md transition-all duration-300 hover:shadow-xl hover:border-red-500 hover:-translate-y-1">
                         <div class="absolute -top-4 -left-4 bg-red-600 text-white rounded-full w-12 h-12 flex items-center justify-center text-2xl font-bold shadow-lg group-hover:scale-110 transition-transform">‚ùå</div>
                        <div class="ml-10">
                            <strong id="sec10-mistake4-title" class="text-lg text-red-300">Resource Requirements:</strong>
                            <p id="sec10-mistake4-desc" class="text-red-400 mt-1">While efficient for its size, running the model locally still requires significant GPU memory (VRAM).</p>
                        </div>
                    </div>
                </div>
            </section>
            
            <!-- Section 11: How to Access -->
            <section class="card">
                <h2 id="sec11-title" class="text-3xl font-bold section-heading">11. How to Access & Use Mixtral üè´</h2>
                <p id="sec11-p1" class="text-lg text-center mb-8 max-w-4xl mx-auto">The open nature of Mixtral means it is available on a wide variety of platforms for developers and users.</p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div>
                        <h3 id="sec11-gov-title" class="subject-category-heading">üìö For Developers & Researchers</h3>
                        <ul id="sec11-gov-list" class="list-disc list-inside space-y-2 text-base">
                           <li>**Hugging Face:** The primary hub for downloading the model weights and using them with the `transformers` library.</li>
                           <li>**Local Inference:** Can be run on consumer GPUs using frameworks like Ollama, vLLM, or LM Studio.</li>
                        </ul>
                    </div>
                    <div>
                        <h3 id="sec11-pvt-title" class="subject-category-heading">üíª For Enterprise & Cloud</h3>
                        <p id="sec11-pvt-p1" class="text-base mb-2">Deploy easily with managed services.</p>
                        <ul id="sec11-pvt-list" class="list-disc list-inside space-y-2 text-base">
                            <li>**Mistral Platform:** Mistral offers its own API for accessing optimized versions of its models.</li>
                            <li>**Cloud Providers:** Mixtral is available on AWS, Google Cloud, Microsoft Azure, and other cloud services.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Section 12: The Future -->
            <section class="card">
                <h2 id="sec12-title" class="text-3xl font-bold section-heading">12. The Future: Efficient & Open AI üöÄ</h2>
                <p id="sec12-p1" class="text-lg mb-6">Mixtral and its Sparse Mixture-of-Experts architecture represent a major breakthrough in creating AI models that are both extremely powerful and computationally efficient. This approach allows for the scaling of model capabilities without a proportional increase in inference cost. The future of open-source AI will likely be dominated by these more efficient architectures, enabling even more powerful models to run on a wider range of hardware, further democratizing access to cutting-edge AI.</p>
                <button id="sec12-career-btn" class="modal-action-button mt-4 inline-block" data-modal-target="careerGrowthModal">View Key Differentiators</button>
            </section>

            <!-- Section 13: Core Concepts -->
            <section class="card bg-black/20">
                <h2 id="sec13-title" class="text-3xl font-bold section-heading">13. Core AI Concepts üìö</h2>
                <p id="sec13-p1" class="text-lg text-center mb-10 max-w-4xl mx-auto">Understanding these core architectural concepts is key to appreciating the innovation behind Mixtral.</p>
                <div id="syllabus-material-grid" class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div class="bg-[#1a2a24] p-6 rounded-lg shadow-lg border border-stone-700">
                        <h3 id="syllabus-oir-title" class="subject-category-heading">Mixture-of-Experts (MoE)</h3>
                        <div id="syllabus-oir-list" class="space-y-4">
                            <!-- Content via JS -->
                        </div>
                    </div>
                    <div class="bg-[#1a2a24] p-6 rounded-lg shadow-lg border border-stone-700">
                        <h3 id="syllabus-ppdt-title" class="subject-category-heading">Sparse vs. Dense Models</h3>
                        <div id="syllabus-ppdt-list" class="space-y-4">
                            <!-- Content via JS -->
                        </div>
                    </div>
                </div>
            </section>

        </main>

        <footer class="text-center mt-16 border-t-2 pt-8 border-yellow-500/20">
            <p id="footer-text" class="text-gray-400 text-lg font-medium">&copy; 2025 | Frontier AI in your hands.</p>
        </footer>

    </div>

    <!-- Modals -->
    <div id="prelimsMainModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <h3 id="prelims-modal-title" class="text-2xl font-bold text-white mb-4">Input: Token Sequence</h3>
            <p id="prelims-modal-p1">The process starts when the user's prompt is converted into a sequence of tokens. Each token is then fed into the model's layers for processing.</p>
        </div>
    </div>

    <div id="mainsMainModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <h3 id="mains-modal-title" class="text-2xl font-bold text-white mb-4">Router: Selects Experts</h3>
            <p id="mains-modal-p1">At each layer of the model, a small "router" network analyzes the token and decides which of the 8 "expert" sub-networks are best suited to process it. It selects the top 2 experts for the task.</p>
        </div>
    </div>

    <div id="interviewModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <h3 id="interview-modal-title" class="text-2xl font-bold text-white mb-4">Output: Combined Result</h3>
            <p id="interview-modal-p1" class="text-base mb-3">The token is processed in parallel by the two selected expert networks. Their outputs are then intelligently combined by the router network to produce the final result for that token before moving on to the next one in the sequence. This process allows the model to have a huge total parameter count while only using a fraction of it for any single input, resulting in high speed and efficiency.</p>
        </div>
    </div>

    <!-- Post Detail Modal -->
    <div id="postDetailModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <div class="flex items-center mb-4">
                <div id="postDetailIcon" class="text-5xl mr-4"></div>
                <h3 id="postDetailTitle" class="text-3xl font-bold text-white"></h3>
            </div>
            <p id="postDetailDescription" class="text-lg text-indigo-200 leading-relaxed"></p>
        </div>
    </div>
    
    <div id="careerGrowthModal" class="modal-overlay">
        <div class="modal-content">
            <button class="modal-close-button">&times;</button>
            <h3 id="career-modal-title" class="text-2xl font-bold text-white mb-6">Key Differentiators of Mixtral</h3>
            <div id="careerPathContainer" class="career-path-timeline"></div>
        </div>
    </div>


    <script>
        document.addEventListener('DOMContentLoaded', () => {
            let interviewChartInstance;
            let currentLang = 'en';

            const serviceDetailsData = {
                'en': {
                    'opensource': { 
                        name: 'Open Source', 
                        icon: 'üåê',
                        description: 'Released under the Apache 2.0 license, Mixtral is free for academic and commercial use, fostering widespread innovation.',
                        cta: 'Learn More'
                    },
                    'smoe': { 
                        name: 'Sparse Mixture-of-Experts', 
                        icon: 'üß©',
                        description: 'A cutting-edge architecture that uses specialized sub-networks ("experts") for different tasks, leading to faster inference and lower costs.',
                        cta: 'Learn More'
                    },
                    'performance': { 
                        name: 'High Performance', 
                        icon: 'üèÜ',
                        description: 'Mixtral 8x7B matches or exceeds the performance of much larger dense models like GPT-3.5 and Llama 2 70B on most benchmarks.',
                        cta: 'Learn More'
                    }
                },
                'hi': {
                    'opensource': { 
                        name: '‡§ì‡§™‡§® ‡§∏‡•ã‡§∞‡•ç‡§∏', 
                        icon: 'üåê',
                        description: '‡§Ö‡§™‡§æ‡§ö‡•á 2.0 ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§§‡§π‡§§ ‡§ú‡§æ‡§∞‡•Ä, ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§Ö‡§ï‡§æ‡§¶‡§Æ‡§ø‡§ï ‡§î‡§∞ ‡§µ‡§æ‡§£‡§ø‡§ú‡•ç‡§Ø‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞ ‡§π‡•à, ‡§ú‡•ã ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§®‡§µ‡§æ‡§ö‡§æ‡§∞ ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§µ‡§æ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§',
                        cta: '‡§î‡§∞ ‡§ú‡§æ‡§®‡•á‡§Ç'
                    },
                    'smoe': { 
                        name: '‡§∏‡•ç‡§™‡§æ‡§∞‡•ç‡§∏ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ö‡§∞-‡§ë‡§´-‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü‡•ç‡§∏', 
                        icon: 'üß©',
                        description: '‡§è‡§ï ‡§Ö‡§§‡•ç‡§Ø‡§æ‡§ß‡•Å‡§®‡§ø‡§ï ‡§µ‡§æ‡§∏‡•ç‡§§‡•Å‡§ï‡§≤‡§æ ‡§ú‡•ã ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§â‡§™-‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ("‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç") ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§§‡•á‡§ú ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§î‡§∞ ‡§ï‡§Æ ‡§≤‡§æ‡§ó‡§§ ‡§Ü‡§§‡•Ä ‡§π‡•à‡•§',
                        cta: '‡§î‡§∞ ‡§ú‡§æ‡§®‡•á‡§Ç'
                    },
                    'performance': { 
                        name: '‡§â‡§ö‡•ç‡§ö ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§®', 
                        icon: 'üèÜ',
                        description: '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ 8x7B ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§Ç‡§∂ ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï ‡§™‡§∞ GPT-3.5 ‡§î‡§∞ ‡§≤‡§æ‡§Æ‡§æ 2 70B ‡§ú‡•à‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡•á ‡§∏‡§ò‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§∏‡•á ‡§Æ‡•á‡§≤ ‡§ñ‡§æ‡§§‡§æ ‡§π‡•à ‡§Ø‡§æ ‡§â‡§∏‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§π‡•à‡•§',
                        cta: '‡§î‡§∞ ‡§ú‡§æ‡§®‡•á‡§Ç'
                    }
                }
            };
            
            const careerPathData = {
                'en': {
                    path: [
                        { rank: "Sparse Mixture-of-Experts (SMoE)", desc: "Instead of a single massive network, Mixtral uses 8 smaller 'expert' networks. For each token, a router selects two experts, drastically reducing the computation needed while maintaining high performance." },
                        { rank: "Cost-Effective Inference", desc: "Although it has 46.7B total parameters, it only uses about 12.9B parameters per token, giving it the speed and cost of a much smaller model." },
                        { rank: "Open and Permissive License", desc: "Released under the Apache 2.0 license, it allows for wide adoption and modification by the community for both research and commercial products." },
                        { rank: "Top-Tier Performance", desc: "It was the first open-source model to match or beat leading proprietary models like GPT-3.5 on a wide range of common benchmarks." }
                    ]
                },
                'hi': {
                    path: [
                        { rank: "‡§∏‡•ç‡§™‡§æ‡§∞‡•ç‡§∏ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ö‡§∞-‡§ë‡§´-‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü‡•ç‡§∏ (SMoE)", desc: "‡§è‡§ï ‡§µ‡§ø‡§∂‡§æ‡§≤ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø, ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ 8 ‡§õ‡•ã‡§ü‡•á '‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û' ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§ü‡•ã‡§ï‡§® ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§è‡§ï ‡§∞‡§æ‡§â‡§ü‡§∞ ‡§¶‡•ã ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç ‡§ï‡§æ ‡§ö‡§Ø‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§â‡§ö‡•ç‡§ö ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§§‡•á ‡§π‡•Å‡§è ‡§ó‡§£‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§∞‡•Ä ‡§ï‡§Æ‡•Ä ‡§Ü‡§§‡•Ä ‡§π‡•à‡•§" },
                        { rank: "‡§≤‡§æ‡§ó‡§§-‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®", desc: "‡§π‡§æ‡§≤‡§æ‡§Ç‡§ï‡§ø ‡§á‡§∏‡§Æ‡•á‡§Ç 46.7B ‡§ï‡•Å‡§≤ ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞ ‡§π‡•à‡§Ç, ‡§Ø‡§π ‡§™‡•ç‡§∞‡§§‡§ø ‡§ü‡•ã‡§ï‡§® ‡§ï‡•á‡§µ‡§≤ ‡§≤‡§ó‡§≠‡§ó 12.9B ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§á‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§õ‡•ã‡§ü‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§ó‡§§‡§ø ‡§î‡§∞ ‡§≤‡§æ‡§ó‡§§ ‡§Æ‡§ø‡§≤‡§§‡•Ä ‡§π‡•à‡•§" },
                        { rank: "‡§ñ‡•Å‡§≤‡§æ ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§ú‡•ç‡§û‡•á‡§Ø ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏", desc: "‡§Ö‡§™‡§æ‡§ö‡•á 2.0 ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§§‡§π‡§§ ‡§ú‡§æ‡§∞‡•Ä, ‡§Ø‡§π ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§î‡§∞ ‡§µ‡§æ‡§£‡§ø‡§ú‡•ç‡§Ø‡§ø‡§ï ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡•ã‡§Ç ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Ö‡§™‡§®‡§æ‡§®‡•á ‡§î‡§∞ ‡§∏‡§Ç‡§∂‡•ã‡§ß‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§" },
                        { rank: "‡§∂‡•Ä‡§∞‡•ç‡§∑-‡§∏‡•ç‡§§‡§∞‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§®", desc: "‡§Ø‡§π ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï ‡§ï‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§™‡§∞ GPT-3.5 ‡§ú‡•à‡§∏‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§Æ‡§æ‡§≤‡§ø‡§ï‡§æ‡§®‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§∏‡•á ‡§Æ‡•á‡§≤ ‡§ñ‡§æ‡§®‡•á ‡§Ø‡§æ ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§π‡§∞‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§™‡§π‡§≤‡§æ ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§Æ‡•â‡§°‡§≤ ‡§•‡§æ‡•§" }
                    ]
                }
            };

            const translations = {
                'en': {
                    'header-title': '‚ìÇÔ∏è Mistral Mixtral: The Ultimate Guide ‚ìÇÔ∏è',
                    'header-subtitle': 'Understanding the Power of Sparse Mixture-of-Experts',
                    'sec1-title': '1. What is Mistral\'s Mixtral? üí°',
                    'sec1-p1': 'Mixtral 8x7B, developed by the French AI company Mistral AI, is a high-quality sparse mixture-of-experts (SMoE) language model. It\'s a powerful open-source model that matches or outperforms much larger models like GPT-3.5 on many benchmarks. Its key innovation is the SMoE architecture, which allows it to have a large number of parameters (46.7B total) but only use a fraction of them for any given token, making it incredibly fast and cost-effective for inference.',
                    'sec2-title': '2. The Mixture-of-Experts (MoE) Architecture üéØ',
                    'sec2-p1': 'Instead of one giant model processing everything, Mixtral uses a "router" to direct each part of a query to specialized "expert" sub-networks, combining their outputs for a final answer.',
                    'sec2-step1-title': 'Input', 'sec2-step1-name': 'Token Sequence', 'sec2-step1-desc': 'User\'s prompt is tokenized',
                    'sec2-step2-title': 'Router', 'sec2-step2-name': 'Selects Experts', 'sec2-step2-desc': 'Router selects 2 of 8 experts for each token',
                    'sec2-step3-title': 'Output', 'sec2-step3-name': 'Combined Result', 'sec2-step3-desc': 'Outputs of the experts are combined',
                    'sec3-title': '3. Who Can Use It? ‚úÖ',
                    'sec3-p1': 'Mixtral is released under the permissive Apache 2.0 license, making it fully open for a wide array of users.',
                    'sec3-age-title': 'Open Source Community:', 'sec3-age-desc': 'Researchers, hobbyists, and developers can freely download, modify, and build upon the model.',
                    'sec3-edu-title': 'Businesses & Startups:', 'sec3-edu-desc': 'Companies can use Mixtral to build commercial applications and services without paying licensing fees.',
                    'sec3-attempts-title': 'Primary Platforms üìä',
                    'sec3-agerelax-list': '<li><strong>Hugging Face:</strong> The easiest way to access the models is through the Hugging Face Hub.</li><li><strong>Cloud Providers:</strong> Available for deployment on major cloud platforms like AWS, Google Cloud, and Azure.</li><li><strong>Local Inference:</strong> Can be run on local machines with sufficient GPU memory, using tools like Ollama or LM Studio.</li>',
                    'sec4-title': '4. Core Capabilities üìö',
                    'sec4-p1': 'Mixtral is a highly proficient language model that excels in multiple domains thanks to its specialized experts.',
                    'gs1-title': 'Code Generation',
                    'gs2-title': 'Multilingual',
                    'gs3-title': 'Long Context',
                    'gs4-title': 'Instruction Following',
                    'sec5-title': '5. How was Mixtral Trained? üèõÔ∏è',
                    'sec5-p1': 'Mixtral was trained on a vast dataset sourced from the open web and fine-tuned for instruction following.',
                    'sec5-hindi-title': '1. Pre-training', 'sec5-hindi-p1': 'The model was trained on a diverse dataset of text and code from the public internet, allowing each of the 8 experts to develop specialized knowledge.',
                    'sec5-essay-title': '2. Fine-Tuning', 'sec5-essay-p1': 'The pretrained base model was then fine-tuned using a combination of Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) to create a helpful, instruction-following chat model.',
                    'sec6-title': '6. Key Applications & Use Cases üåü',
                    'sec6-p1': 'Mixtral\'s blend of high performance and efficiency makes it ideal for a wide range of real-world applications.',
                    'sec6-eng-title': 'Enterprise Chatbots', 'sec6-eng-list': '<li>Building powerful internal and external chatbots.</li><li>Retrieval-Augmented Generation (RAG) on company documents.</li>',
                    'sec6-elec-title': 'Software Development', 'sec6-elec-list': '<li>High-performance code completion.</li><li>Generating and debugging complex code.</li><li>Powering developer assistant tools.</li>',
                    'sec6-naic-title': 'Content & Analysis', 'sec6-naic-list': '<li>Summarizing long reports and articles.</li><li>Drafting emails, marketing copy, and creative text.</li><li>Classifying and analyzing text data at scale.</li>',
                    'sec7-title': '7. Performance & Benchmarks üéôÔ∏è',
                    'sec7-p1': 'Mixtral 8x7B has demonstrated exceptional performance, matching or outperforming much larger, dense models like Llama 2 70B and GPT-3.5 across a wide array of standard benchmarks.',
                    'sec7-qualities-title': 'Key Benchmarks:',
                    'sec7-qualities-list': '<li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üß†</span><div><strong class="text-white">MMLU (Reasoning):</strong> Outperforms Llama 2 70B, showcasing its strong general knowledge and reasoning abilities.</div></li><li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üíª</span><div><strong class="text-white">HumanEval (Coding):</strong> Significantly outperforms larger models, establishing it as a top-tier open-source code generation model.</div></li><li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üî¢</span><div><strong class="text-white">GSM8K (Math):</strong> Achieves a very high score on grade-school math problems, demonstrating strong mathematical reasoning.</div></li>',
                    'sec8-title': '8. Prompting Mixtral: Best Practices üìà',
                    'sec8-p1': 'To get the best performance from the Mixtral-Instruct model, it\'s important to follow the specific chat template it was trained on.',
                    'sec8-steps-title': 'üìö The Chat Template:',
                    'sec8-step1-title': 'Use Instruction Tags', 'sec8-step1-desc': 'Wrap your prompts inside `[INST]` and `[/INST]` tags. For example: `[INST] What is the capital of France? [/INST]`.',
                    'sec8-step2-title': 'Conversational Turns', 'sec8-step2-desc': 'For a multi-turn conversation, you can chain prompts and responses together, ensuring each user prompt is correctly tagged.',
                    'sec8-revision-title': 'üîÑ General Tips:',
                    'sec8-revision-list': '<li><strong>Be Clear and Concise:</strong> Provide clear and direct instructions for the best results.</li><li><strong>Provide Context:</strong> For more complex tasks, include relevant context or examples within your prompt.</li>',
                    'sec9-title': '9. Model Evolution üóìÔ∏è',
                    'sec9-p1': 'The Mixtral series represents a significant architectural evolution in Mistral AI\'s family of open-source models.',
                    'sec9-step1-title': 'Mistral 7B', 'sec9-step1-desc': '<strong>Timeline:</strong> September 2023. Mistral\'s first model, which outperformed much larger models like Llama 2 13B.',
                    'sec9-step2-title': 'Mixtral 8x7B', 'sec9-step2-desc': '<strong>Timeline:</strong> December 2023. The release of the first high-quality, open-source Sparse Mixture-of-Experts model, changing the landscape of efficient AI.',
                    'sec9-step3-title': 'Mixtral 8x22B', 'sec9-step3-desc': '<strong>Timeline:</strong> April 2024. A new, even larger and more capable MoE model released with an open-but-not-commercial license, pushing performance even further.',
                    'sec10-title': '10. Limitations & Considerations üö´',
                    'sec10-p1': 'While Mixtral is highly capable, it is important to be aware of the general limitations of current LLMs.',
                    'sec10-mistake1-title': 'Factual Accuracy:', 'sec10-mistake1-desc': 'Like all LLMs, Mixtral can "hallucinate" and produce incorrect information. It should not be relied upon for factually critical applications without verification.',
                    'sec10-mistake2-title': 'Potential for Bias:', 'sec10-mistake2-desc': 'The model is trained on web data and may reflect the biases present in that data. Careful implementation and guardrails are needed.',
                    'sec10-mistake3-title': 'No Inherent Safety Filter:', 'sec10-mistake3-desc': 'The base Mixtral model is not moderated. Developers building applications must implement their own safety and moderation layers.',
                    'sec10-mistake4-title': 'Resource Requirements:', 'sec10-mistake4-desc': 'While efficient for its size, running the model locally still requires significant GPU memory (VRAM).',
                    'sec11-title': '11. How to Access & Use Mixtral üè´',
                    'sec11-p1': 'The open nature of Mixtral means it is available on a wide variety of platforms for developers and users.',
                    'sec11-gov-title': 'üìö For Developers & Researchers', 'sec11-gov-list': '<li>**Hugging Face:** The primary hub for downloading the model weights and using them with the `transformers` library.</li><li>**Local Inference:** Can be run on consumer GPUs using frameworks like Ollama, vLLM, or LM Studio.</li>',
                    'sec11-pvt-title': 'üíª For Enterprise & Cloud', 'sec11-pvt-p1': 'Deploy easily with managed services.', 'sec11-pvt-list': '<li>**Mistral Platform:** Mistral offers its own API for accessing optimized versions of its models.</li><li>**Cloud Providers:** Mixtral is available on AWS, Google Cloud, Microsoft Azure, and other cloud services.</li>',
                    'sec12-title': '12. The Future: Efficient & Open AI üöÄ',
                    'sec12-p1': 'Mixtral and its Sparse Mixture-of-Experts architecture represent a major breakthrough in creating AI models that are both extremely powerful and computationally efficient. This approach allows for the scaling of model capabilities without a proportional increase in inference cost. The future of open-source AI will likely be dominated by these more efficient architectures, enabling even more powerful models to run on a wider range of hardware, further democratizing access to cutting-edge AI.',
                    'sec12-career-btn': 'View Key Differentiators',
                    'sec13-title': '13. Core AI Concepts üìö',
                    'sec13-p1': 'Understanding these core architectural concepts is key to appreciating the innovation behind Mixtral.',
                    'syllabus-oir-title': 'Mixture-of-Experts (MoE)',
                    'syllabus-oir-list': '<div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üß©</span><div class="flex-grow">Expert Sub-networks</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">Notes</button><button class="lectures-btn">Lectures</button></div></div><div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üß≠</span><div class="flex-grow">Router Network</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">Notes</button><button class="lectures-btn">Lectures</button></div></div>',
                    'syllabus-ppdt-title': 'Sparse vs. Dense Models',
                    'syllabus-ppdt-list': '<div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üß±</span><div class="flex-grow">Dense Models (e.g., Llama 2)</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">Notes</button><button class="lectures-btn">Lectures</button></div></div><div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">‚ú®</span><div class="flex-grow">Sparse Models (e.g., Mixtral)</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">Notes</button><button class="lectures-btn">Lectures</button></div></div>',
                    'footer-text': '&copy; 2025 | Frontier AI in your hands.',
                    'interviewChartData': {
                        labels: ['MMLU', 'GSM8K', 'HumanEval', 'MBPP'],
                        data: [70.6, 61.1, 40.2, 53.7] // Mixtral 8x7B scores
                    }
                },
                'hi': {
                    'header-title': '‚ìÇÔ∏è ‡§Æ‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡§≤ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤: ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§ó‡§æ‡§á‡§° ‚ìÇÔ∏è',
                    'header-subtitle': '‡§∏‡•ç‡§™‡§æ‡§∞‡•ç‡§∏ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ö‡§∞-‡§ë‡§´-‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü‡•ç‡§∏ ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡§æ',
                    'sec1-title': '1. ‡§Æ‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡§≤ ‡§ï‡§æ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à? üí°',
                    'sec1-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ 8x7B, ‡§´‡•ç‡§∞‡§æ‡§Ç‡§∏‡•Ä‡§∏‡•Ä ‡§è‡§Ü‡§à ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§Æ‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡§≤ ‡§è‡§Ü‡§à ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§, ‡§è‡§ï ‡§â‡§ö‡•ç‡§ö-‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§µ‡§æ‡§≤‡§æ ‡§∏‡•ç‡§™‡§æ‡§∞‡•ç‡§∏ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ö‡§∞-‡§ë‡§´-‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü‡•ç‡§∏ (‡§è‡§∏‡§è‡§Æ‡§ì‡§à) ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§è‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§Æ‡•â‡§°‡§≤ ‡§π‡•à ‡§ú‡•ã ‡§ï‡§à ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï ‡§™‡§∞ GPT-3.5 ‡§ú‡•à‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡•á ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§∏‡•á ‡§Æ‡•á‡§≤ ‡§ñ‡§æ‡§§‡§æ ‡§π‡•à ‡§Ø‡§æ ‡§â‡§®‡§∏‡•á ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ ‡§á‡§∏‡§ï‡§æ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§®‡§µ‡§æ‡§ö‡§æ‡§∞ ‡§è‡§∏‡§è‡§Æ‡§ì‡§à ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§π‡•à, ‡§ú‡•ã ‡§á‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞ (‡§ï‡•Å‡§≤ 46.7B) ‡§∞‡§ñ‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡§æ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§ï‡§ø‡§∏‡•Ä ‡§¶‡§ø‡§è ‡§ó‡§è ‡§ü‡•ã‡§ï‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§®‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡•á‡§µ‡§≤ ‡§è‡§ï ‡§Ö‡§Ç‡§∂ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§á‡§∏‡•á ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§§‡•á‡§ú ‡§î‡§∞ ‡§≤‡§æ‡§ó‡§§ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à‡•§',
                    'sec2-title': '2. ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ö‡§∞-‡§ë‡§´-‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü‡•ç‡§∏ (‡§è‡§Æ‡§ì‡§à) ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ üéØ',
                    'sec2-p1': '‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§è‡§ï ‡§µ‡§ø‡§∂‡§æ‡§≤ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø, ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§è‡§ï "‡§∞‡§æ‡§â‡§ü‡§∞" ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§§‡§æ‡§ï‡§ø ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§≠‡§æ‡§ó ‡§ï‡•ã ‡§µ‡§ø‡§∂‡•á‡§∑ "‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û" ‡§â‡§™-‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡•á, ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§®‡§ï‡•á ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§ï‡•ã ‡§Æ‡§ø‡§≤‡§æ‡§ï‡§∞‡•§',
                    'sec2-step1-title': '‡§á‡§®‡§™‡•Å‡§ü', 'sec2-step1-name': '‡§ü‡•ã‡§ï‡§® ‡§Ö‡§®‡•Å‡§ï‡•ç‡§∞‡§Æ', 'sec2-step1-desc': '‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§ü‡•ã‡§ï‡§®‡§æ‡§á‡§ú‡§º ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à',
                    'sec2-step2-title': '‡§∞‡§æ‡§â‡§ü‡§∞', 'sec2-step2-name': '‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç ‡§ï‡§æ ‡§ö‡§Ø‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à', 'sec2-step2-desc': '‡§∞‡§æ‡§â‡§ü‡§∞ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§ü‡•ã‡§ï‡§® ‡§ï‡•á ‡§≤‡§ø‡§è 8 ‡§Æ‡•á‡§Ç ‡§∏‡•á 2 ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç ‡§ï‡§æ ‡§ö‡§Ø‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à',
                    'sec2-step3-title': '‡§Ü‡§â‡§ü‡§™‡•Å‡§ü', 'sec2-step3-name': '‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ', 'sec2-step3-desc': '‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§π‡•à‡§Ç',
                    'sec3-title': '3. ‡§á‡§∏‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•å‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à? ‚úÖ',
                    'sec3-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§ú‡•ç‡§û‡•á‡§Ø ‡§Ö‡§™‡§æ‡§ö‡•á 2.0 ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§§‡§π‡§§ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§á‡§∏‡•á ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§ï‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ñ‡•Å‡§≤‡§æ ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à‡•§',
                    'sec3-age-title': '‡§ì‡§™‡§® ‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø:', 'sec3-age-desc': '‡§∂‡•ã‡§ß‡§ï‡§∞‡•ç‡§§‡§æ, ‡§π‡•â‡§¨‡•Ä‡§∏‡•ç‡§ü ‡§î‡§∞ ‡§°‡•á‡§µ‡§≤‡§™‡§∞‡•ç‡§∏ ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°, ‡§∏‡§Ç‡§∂‡•ã‡§ß‡§ø‡§§ ‡§î‡§∞ ‡§â‡§∏ ‡§™‡§∞ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§',
                    'sec3-edu-title': '‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§î‡§∞ ‡§∏‡•ç‡§ü‡§æ‡§∞‡•ç‡§ü‡§Ö‡§™:', 'sec3-edu-desc': '‡§ï‡§Ç‡§™‡§®‡§ø‡§Ø‡§æ‡§Ç ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§ï‡§æ ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§ø‡§è ‡§¨‡§ø‡§®‡§æ ‡§µ‡§æ‡§£‡§ø‡§ú‡•ç‡§Ø‡§ø‡§ï ‡§è‡§™‡•ç‡§≤‡§ø‡§ï‡•á‡§∂‡§® ‡§î‡§∞ ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç‡•§',
                    'sec3-attempts-title': '‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ üìä',
                    'sec3-agerelax-list': '<li><strong>‡§π‡§ó‡§ø‡§Ç‡§ó ‡§´‡•á‡§∏:</strong> ‡§Æ‡•â‡§°‡§≤ ‡§§‡§ï ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•á ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ü‡§∏‡§æ‡§® ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§π‡§ó‡§ø‡§Ç‡§ó ‡§´‡•á‡§∏ ‡§π‡§¨ ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§π‡•à‡•§</li><li><strong>‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§™‡•ç‡§∞‡§¶‡§æ‡§§‡§æ:</strong> ‡§è‡§°‡§¨‡•ç‡§≤‡•ç‡§Ø‡•Ç‡§è‡§∏, ‡§ó‡•Ç‡§ó‡§≤ ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§î‡§∞ ‡§è‡§ú‡§º‡•ç‡§Ø‡•ã‡§∞ ‡§ú‡•à‡§∏‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡§æ‡§∞‡•ç‡§Æ‡•ã‡§Ç ‡§™‡§∞ ‡§™‡§∞‡§ø‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à‡•§</li><li><strong>‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®:</strong> ‡§ì‡§≤‡§æ‡§Æ‡§æ ‡§Ø‡§æ ‡§è‡§≤‡§è‡§Æ ‡§∏‡•ç‡§ü‡•Ç‡§°‡§ø‡§Ø‡•ã ‡§ú‡•à‡§∏‡•á ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ú‡•Ä‡§™‡•Ä‡§Ø‡•Ç ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§µ‡§æ‡§≤‡•Ä ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§Æ‡§∂‡•Ä‡§®‡•ã‡§Ç ‡§™‡§∞ ‡§ö‡§≤‡§æ‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§</li>',
                    'sec4-title': '4. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§è‡§Ç üìö',
                    'sec4-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§è‡§ï ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§ï‡•Å‡§∂‡§≤ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§π‡•à ‡§ú‡•ã ‡§Ö‡§™‡§®‡•á ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ï‡§à ‡§°‡•ã‡§Æ‡•á‡§® ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü‡§§‡§æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§',
                    'gs1-title': '‡§ï‡•ã‡§° ‡§ú‡§®‡§∞‡•á‡§∂‡§®',
                    'gs2-title': '‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä',
                    'gs3-title': '‡§≤‡§Ç‡§¨‡§æ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠',
                    'gs4-title': '‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂ ‡§ï‡§æ ‡§™‡§æ‡§≤‡§®',
                    'sec5-title': '5. ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡•ã ‡§ï‡•à‡§∏‡•á ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ? üèõÔ∏è',
                    'sec5-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡•ã ‡§ñ‡•Å‡§≤‡•á ‡§µ‡•á‡§¨ ‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§è‡§ï ‡§µ‡§ø‡§∂‡§æ‡§≤ ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ ‡§î‡§∞ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂ ‡§™‡§æ‡§≤‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§†‡•Ä‡§ï-‡§†‡•Ä‡§ï ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ‡•§',
                    'sec5-hindi-title': '1. ‡§™‡•Ç‡§∞‡•ç‡§µ-‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£', 'sec5-hindi-p1': '‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§∏‡•á ‡§™‡§æ‡§† ‡§î‡§∞ ‡§ï‡•ã‡§° ‡§ï‡•á ‡§è‡§ï ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ, ‡§ú‡§ø‡§∏‡§∏‡•á 8 ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§ï‡•ã ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§ú‡•ç‡§û‡§æ‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§Æ‡§ø‡§≤‡•Ä‡•§',
                    'sec5-essay-title': '2. ‡§´‡§æ‡§á‡§®-‡§ü‡•ç‡§Ø‡•Ç‡§®‡§ø‡§Ç‡§ó', 'sec5-essay-p1': '‡§™‡•Ç‡§∞‡•ç‡§µ-‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§Ü‡§ß‡§æ‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§§‡§¨ ‡§è‡§ï ‡§∏‡§π‡§æ‡§Ø‡§ï, ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂-‡§™‡§æ‡§≤‡§® ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§ö‡•à‡§ü ‡§Æ‡•â‡§°‡§≤ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§∞‡•ç‡§Ø‡§µ‡•á‡§ï‡•ç‡§∑‡§ø‡§§ ‡§´‡§æ‡§á‡§®-‡§ü‡•ç‡§Ø‡•Ç‡§®‡§ø‡§Ç‡§ó (‡§è‡§∏‡§è‡§´‡§ü‡•Ä) ‡§î‡§∞ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§µ‡§∞‡•Ä‡§Ø‡§§‡§æ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§® (‡§°‡•Ä‡§™‡•Ä‡§ì) ‡§ï‡•á ‡§∏‡§Ç‡§Ø‡•ã‡§ú‡§® ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§†‡•Ä‡§ï-‡§†‡•Ä‡§ï ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ‡•§',
                    'sec6-title': '6. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•á ‡§Æ‡§æ‡§Æ‡§≤‡•á üåü',
                    'sec6-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡§æ ‡§â‡§ö‡•ç‡§ö ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§î‡§∞ ‡§¶‡§ï‡•ç‡§∑‡§§‡§æ ‡§ï‡§æ ‡§Æ‡§ø‡§∂‡•ç‡§∞‡§£ ‡§á‡§∏‡•á ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§¶‡§∞‡•ç‡§∂ ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à‡•§',
                    'sec6-eng-title': '‡§è‡§Ç‡§ü‡§∞‡§™‡•ç‡§∞‡§æ‡§á‡§ú ‡§ö‡•à‡§ü‡§¨‡•â‡§ü', 'sec6-eng-list': '<li>‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§Ü‡§Ç‡§§‡§∞‡§ø‡§ï ‡§î‡§∞ ‡§¨‡§æ‡§π‡§∞‡•Ä ‡§ö‡•à‡§ü‡§¨‡•â‡§ü ‡§¨‡§®‡§æ‡§®‡§æ‡•§</li><li>‡§ï‡§Ç‡§™‡§®‡•Ä ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡•ã‡§Ç ‡§™‡§∞ ‡§™‡•Å‡§®‡§∞‡•ç‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§‡§ø-‡§∏‡§Ç‡§µ‡§∞‡•ç‡§ß‡§ø‡§§ ‡§™‡•Ä‡§¢‡§º‡•Ä (‡§Ü‡§∞‡§è‡§ú‡•Ä)‡•§</li>',
                    'sec6-elec-title': '‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§µ‡§ø‡§ï‡§æ‡§∏', 'sec6-elec-list': '<li>‡§â‡§ö‡•ç‡§ö-‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•ã‡§° ‡§™‡•Ç‡§∞‡•ç‡§£‡§§‡§æ‡•§</li><li>‡§ú‡§ü‡§ø‡§≤ ‡§ï‡•ã‡§° ‡§¨‡§®‡§æ‡§®‡§æ ‡§î‡§∞ ‡§°‡•Ä‡§¨‡§ó ‡§ï‡§∞‡§®‡§æ‡•§</li><li>‡§°‡•á‡§µ‡§≤‡§™‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§ï‡•ç‡§§‡§ø ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡§æ‡•§</li>',
                    'sec6-naic-title': '‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§î‡§∞ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£', 'sec6-naic-list': '<li>‡§≤‡§Ç‡§¨‡•Ä ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§î‡§∞ ‡§≤‡•á‡§ñ‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡•§</li><li>‡§à‡§Æ‡•á‡§≤, ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü‡§ø‡§Ç‡§ó ‡§ï‡•â‡§™‡•Ä ‡§î‡§∞ ‡§∞‡§ö‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡§æ‡§† ‡§ï‡§æ ‡§Æ‡§∏‡•å‡§¶‡§æ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡§æ‡•§</li><li>‡§¨‡§°‡§º‡•á ‡§™‡•à‡§Æ‡§æ‡§®‡•á ‡§™‡§∞ ‡§™‡§æ‡§† ‡§°‡•á‡§ü‡§æ ‡§ï‡§æ ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£ ‡§î‡§∞ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£‡•§</li>',
                    'sec7-title': '7. ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§î‡§∞ ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï üéôÔ∏è',
                    'sec7-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ 8x7B ‡§®‡•á ‡§Ö‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§Æ‡§æ‡§®‡§ï ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï ‡§ï‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§Æ‡•á‡§Ç ‡§≤‡§æ‡§Æ‡§æ 2 70B ‡§î‡§∞ GPT-3.5 ‡§ú‡•à‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡•á, ‡§∏‡§ò‡§® ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§∏‡•á ‡§Æ‡•á‡§≤ ‡§ñ‡§æ‡§§‡§æ ‡§π‡•à ‡§Ø‡§æ ‡§â‡§®‡§∏‡•á ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§',
                    'sec7-qualities-title': '‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï:',
                    'sec7-qualities-list': '<li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üß†</span><div><strong class="text-white">‡§è‡§Æ‡§è‡§Æ‡§è‡§≤‡§Ø‡•Ç (‡§§‡§∞‡•ç‡§ï):</strong> ‡§≤‡§æ‡§Æ‡§æ 2 70B ‡§∏‡•á ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§á‡§∏‡§ï‡•á ‡§Æ‡§ú‡§¨‡•Ç‡§§ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ú‡•ç‡§û‡§æ‡§® ‡§î‡§∞ ‡§§‡§∞‡•ç‡§ï ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§</div></li><li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üíª</span><div><strong class="text-white">‡§π‡•ç‡§Ø‡•Ç‡§Æ‡§®‡§á‡§µ‡§≤ (‡§ï‡•ã‡§°‡§ø‡§Ç‡§ó):</strong> ‡§¨‡§°‡§º‡•á ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§∏‡•á ‡§ï‡§æ‡§´‡•Ä ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§á‡§∏‡•á ‡§è‡§ï ‡§∂‡•Ä‡§∞‡•ç‡§∑ ‡§∏‡•ç‡§§‡§∞‡•Ä‡§Ø ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§ï‡•ã‡§° ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§</div></li><li class="flex items-start"><span class="text-2xl text-[#34A853] mr-3">üî¢</span><div><strong class="text-white">‡§ú‡•Ä‡§è‡§∏‡§è‡§Æ8‡§ï‡•á (‡§ó‡§£‡§ø‡§§):</strong> ‡§ó‡•ç‡§∞‡•á‡§°-‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ó‡§£‡§ø‡§§ ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§™‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡•ç‡§ï‡•ã‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§Æ‡§ú‡§¨‡•Ç‡§§ ‡§ó‡§£‡§ø‡§§‡•Ä‡§Ø ‡§§‡§∞‡•ç‡§ï ‡§ï‡§æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§</div></li>',
                    'sec8-title': '8. ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡•ã ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§ï‡§∞‡§®‡§æ: ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§Ö‡§≠‡•ç‡§Ø‡§æ‡§∏ üìà',
                    'sec8-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤-‡§á‡§Ç‡§∏‡•ç‡§ü‡•ç‡§∞‡§ï‡•ç‡§ü ‡§Æ‡•â‡§°‡§≤ ‡§∏‡•á ‡§∏‡§∞‡•ç‡§µ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§† ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§â‡§∏ ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§ö‡•à‡§ü ‡§ü‡•á‡§Æ‡•ç‡§™‡§≤‡•á‡§ü ‡§ï‡§æ ‡§™‡§æ‡§≤‡§® ‡§ï‡§∞‡§®‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à ‡§ú‡§ø‡§∏ ‡§™‡§∞ ‡§á‡§∏‡•á ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ‡•§',
                    'sec8-steps-title': 'üìö ‡§ö‡•à‡§ü ‡§ü‡•á‡§Æ‡•ç‡§™‡§≤‡•á‡§ü:',
                    'sec8-step1-title': '‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂ ‡§ü‡•à‡§ó ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç', 'sec8-step1-desc': '‡§Ö‡§™‡§®‡•á ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§ï‡•ã `[INST]` ‡§î‡§∞ `[/INST]` ‡§ü‡•à‡§ó ‡§ï‡•á ‡§Ö‡§Ç‡§¶‡§∞ ‡§≤‡§™‡•á‡§ü‡•á‡§Ç‡•§ ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è: `[INST] ‡§´‡•ç‡§∞‡§æ‡§Ç‡§∏ ‡§ï‡•Ä ‡§∞‡§æ‡§ú‡§ß‡§æ‡§®‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à? [/INST]`‡•§',
                    'sec8-step2-title': '‡§∏‡§Ç‡§µ‡§æ‡§¶‡•Ä ‡§Æ‡•ã‡§°‡§º', 'sec8-step2-desc': '‡§è‡§ï ‡§¨‡§π‡•Å-‡§Æ‡•ã‡§°‡§º ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§Ü‡§™ ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§î‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§è‡§ï ‡§∏‡§æ‡§• ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ‡§¨‡§¶‡•ç‡§ß ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§Ø‡§π ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•Å‡§è ‡§ï‡§ø ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§∏‡§π‡•Ä ‡§¢‡§Ç‡§ó ‡§∏‡•á ‡§ü‡•à‡§ó ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§',
                    'sec8-revision-title': 'üîÑ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§∏‡•Å‡§ù‡§æ‡§µ:',
                    'sec8-revision-list': '<li><strong>‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§î‡§∞ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∞‡§π‡•á‡§Ç:</strong> ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§î‡§∞ ‡§∏‡•Ä‡§ß‡•á ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§</li><li><strong>‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç:</strong> ‡§Ö‡§ß‡§ø‡§ï ‡§ú‡§ü‡§ø‡§≤ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§Ö‡§™‡§®‡•á ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§ï‡•á ‡§≠‡•Ä‡§§‡§∞ ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§Ø‡§æ ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§</li>',
                    'sec9-title': '9. ‡§Æ‡•â‡§°‡§≤ ‡§µ‡§ø‡§ï‡§æ‡§∏ üóìÔ∏è',
                    'sec9-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§Æ‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡§≤ ‡§è‡§Ü‡§à ‡§ï‡•á ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§µ‡§æ‡§∏‡•ç‡§§‡•Å‡§ï‡§≤‡§æ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§§‡•ç‡§µ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§',
                    'sec9-step1-title': '‡§Æ‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡§≤ 7B', 'sec9-step1-desc': '<strong>‡§∏‡§Æ‡§Ø‡§∞‡•á‡§ñ‡§æ:</strong> ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ 2023‡•§ ‡§Æ‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡§≤ ‡§ï‡§æ ‡§™‡§π‡§≤‡§æ ‡§Æ‡•â‡§°‡§≤, ‡§ú‡§ø‡§∏‡§®‡•á ‡§≤‡§æ‡§Æ‡§æ 2 13B ‡§ú‡•à‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡•á ‡§Æ‡•â‡§°‡§≤‡•ã‡§Ç ‡§∏‡•á ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§ø‡§Ø‡§æ‡•§',
                    'sec9-step2-title': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ 8x7B', 'sec9-step2-desc': '<strong>‡§∏‡§Æ‡§Ø‡§∞‡•á‡§ñ‡§æ:</strong> ‡§¶‡§ø‡§∏‡§Ç‡§¨‡§∞ 2023‡•§ ‡§™‡§π‡§≤‡•á ‡§â‡§ö‡•ç‡§ö-‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§µ‡§æ‡§≤‡•á, ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§∏‡•ç‡§™‡§æ‡§∞‡•ç‡§∏ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ö‡§∞-‡§ë‡§´-‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü‡•ç‡§∏ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§∞‡§ø‡§≤‡•Ä‡§ú, ‡§ï‡•Å‡§∂‡§≤ ‡§è‡§Ü‡§à ‡§ï‡•á ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø ‡§ï‡•ã ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§',
                    'sec9-step3-title': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ 8x22B', 'sec9-step3-desc': '<strong>‡§∏‡§Æ‡§Ø‡§∞‡•á‡§ñ‡§æ:</strong> ‡§Ö‡§™‡•ç‡§∞‡•à‡§≤ 2024‡•§ ‡§è‡§ï ‡§®‡§Ø‡§æ, ‡§î‡§∞ ‡§≠‡•Ä ‡§¨‡§°‡§º‡§æ ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§è‡§Æ‡§ì‡§à ‡§Æ‡•â‡§°‡§≤ ‡§è‡§ï ‡§ñ‡•Å‡§≤‡•á-‡§≤‡•á‡§ï‡§ø‡§®-‡§ó‡•à‡§∞-‡§µ‡§æ‡§£‡§ø‡§ú‡•ç‡§Ø‡§ø‡§ï ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ, ‡§ú‡•ã ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•ã ‡§î‡§∞ ‡§≠‡•Ä ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡§æ‡§§‡§æ ‡§π‡•à‡•§',
                    'sec10-title': '10. ‡§∏‡•Ä‡§Æ‡§æ‡§è‡§Ç ‡§î‡§∞ ‡§µ‡§ø‡§ö‡§æ‡§∞ üö´',
                    'sec10-p1': '‡§π‡§æ‡§≤‡§æ‡§Ç‡§ï‡§ø ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§è‡§≤‡§è‡§≤‡§è‡§Æ ‡§ï‡•Ä ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§∏‡•Ä‡§Æ‡§æ‡§ì‡§Ç ‡§∏‡•á ‡§Ö‡§µ‡§ó‡§§ ‡§π‡•ã‡§®‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§',
                    'sec10-mistake1-title': '‡§§‡§•‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ:', 'sec10-mistake1-desc': '‡§∏‡§≠‡•Ä ‡§è‡§≤‡§è‡§≤‡§è‡§Æ ‡§ï‡•Ä ‡§§‡§∞‡§π, ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ "‡§Æ‡§§‡§ø‡§≠‡•ç‡§∞‡§Æ" ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§ó‡§≤‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§® ‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§§‡§•‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§á‡§∏ ‡§™‡§∞ ‡§≠‡§∞‡•ã‡§∏‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§',
                    'sec10-mistake2-title': '‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§ó‡•ç‡§∞‡§π ‡§ï‡•Ä ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§®‡§æ:', 'sec10-mistake2-desc': '‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§µ‡•á‡§¨ ‡§°‡•á‡§ü‡§æ ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§Ø‡§π ‡§â‡§∏ ‡§°‡•á‡§ü‡§æ ‡§Æ‡•á‡§Ç ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§ó‡•ç‡§∞‡§π‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§¨‡§ø‡§Ç‡§¨‡§ø‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§∏‡§æ‡§µ‡§ß‡§æ‡§®‡•Ä‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§î‡§∞ ‡§∞‡•á‡§≤‡§ø‡§Ç‡§ó ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•à‡•§',
                    'sec10-mistake3-title': '‡§ï‡•ã‡§à ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§®‡§ø‡§π‡§ø‡§§ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§´‡§º‡§ø‡§≤‡•ç‡§ü‡§∞ ‡§®‡§π‡•Ä‡§Ç:', 'sec10-mistake3-desc': '‡§Ü‡§ß‡§æ‡§∞ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§Æ‡•â‡§°‡§∞‡•á‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§è‡§™‡•ç‡§≤‡§ø‡§ï‡•á‡§∂‡§® ‡§¨‡§®‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§°‡•á‡§µ‡§≤‡§™‡§∞‡•ç‡§∏ ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ç‡§µ‡§Ø‡§Ç ‡§ï‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§Æ‡•â‡§°‡§∞‡•á‡§∂‡§® ‡§™‡§∞‡§§‡•á‡§Ç ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§®‡•Ä ‡§π‡•ã‡§Ç‡§ó‡•Ä‡•§',
                    'sec10-mistake4-title': '‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§è‡§Å:', 'sec10-mistake4-desc': '‡§π‡§æ‡§≤‡§æ‡§Ç‡§ï‡§ø ‡§Ö‡§™‡§®‡•á ‡§Ü‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•Å‡§∂‡§≤, ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ö‡§≤‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ú‡•Ä‡§™‡•Ä‡§Ø‡•Ç ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä (‡§µ‡•Ä‡§Ü‡§∞‡§è‡§è‡§Æ) ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§',
                    'sec11-title': '11. ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§§‡§ï ‡§ï‡•à‡§∏‡•á ‡§™‡§π‡•Å‡§Å‡§ö‡•á‡§Ç ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç üè´',
                    'sec11-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡•Ä ‡§ñ‡•Å‡§≤‡•Ä ‡§™‡•ç‡§∞‡§ï‡•É‡§§‡§ø ‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§π‡•à ‡§ï‡§ø ‡§Ø‡§π ‡§°‡•á‡§µ‡§≤‡§™‡§∞‡•ç‡§∏ ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡§æ‡§∞‡•ç‡§Æ‡•ã‡§Ç ‡§™‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à‡•§',
                    'sec11-gov-title': 'üìö ‡§°‡•á‡§µ‡§≤‡§™‡§∞‡•ç‡§∏ ‡§î‡§∞ ‡§∂‡•ã‡§ß‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è', 'sec11-gov-list': '<li><strong>‡§π‡§ó‡§ø‡§Ç‡§ó ‡§´‡•á‡§∏:</strong> `‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§´‡§æ‡§∞‡•ç‡§Æ‡§∞` ‡§≤‡§æ‡§á‡§¨‡•ç‡§∞‡•á‡§∞‡•Ä ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Æ‡•â‡§°‡§≤ ‡§≠‡§æ‡§∞ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ ‡§â‡§®‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡•§</li><li><strong>‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®:</strong> ‡§ì‡§≤‡§æ‡§Æ‡§æ, ‡§µ‡•Ä‡§è‡§≤‡§è‡§≤‡§è‡§Æ, ‡§Ø‡§æ ‡§è‡§≤‡§è‡§Æ ‡§∏‡•ç‡§ü‡•Ç‡§°‡§ø‡§Ø‡•ã ‡§ú‡•à‡§∏‡•á ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§â‡§™‡§≠‡•ã‡§ï‡•ç‡§§‡§æ ‡§ú‡•Ä‡§™‡•Ä‡§Ø‡•Ç ‡§™‡§∞ ‡§ö‡§≤‡§æ‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§</li>',
                    'sec11-pvt-title': 'üíª ‡§â‡§¶‡•ç‡§Ø‡§Æ ‡§î‡§∞ ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§ï‡•á ‡§≤‡§ø‡§è', 'sec11-pvt-p1': '‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Ü‡§∏‡§æ‡§®‡•Ä ‡§∏‡•á ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§', 'sec11-pvt-list': '<li><strong>‡§Æ‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡§≤ ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ:</strong> ‡§Æ‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡§≤ ‡§Ö‡§™‡§®‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£‡•ã‡§Ç ‡§§‡§ï ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§™‡§®‡§æ ‡§∏‡•ç‡§µ‡§Ø‡§Ç ‡§ï‡§æ ‡§è‡§™‡•Ä‡§Ü‡§à ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§</li><li><strong>‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§™‡•ç‡§∞‡§¶‡§æ‡§§‡§æ:</strong> ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§è‡§°‡§¨‡•ç‡§≤‡•ç‡§Ø‡•Ç‡§è‡§∏, ‡§ó‡•Ç‡§ó‡§≤ ‡§ï‡•ç‡§≤‡§æ‡§â‡§°, ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§∏‡•â‡§´‡•ç‡§ü ‡§è‡§ú‡§º‡•ç‡§Ø‡•ã‡§∞ ‡§î‡§∞ ‡§Ö‡§®‡•ç‡§Ø ‡§ï‡•ç‡§≤‡§æ‡§â‡§° ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§™‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à‡•§</li>',
                    'sec12-title': '12. ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø: ‡§ï‡•Å‡§∂‡§≤ ‡§î‡§∞ ‡§ñ‡•Å‡§≤‡§æ ‡§è‡§Ü‡§à üöÄ',
                    'sec12-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§î‡§∞ ‡§á‡§∏‡§ï‡•Ä ‡§∏‡•ç‡§™‡§æ‡§∞‡•ç‡§∏ ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ö‡§∞-‡§ë‡§´-‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü‡•ç‡§∏ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§è‡§Ü‡§à ‡§Æ‡•â‡§°‡§≤ ‡§¨‡§®‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§¨‡§°‡§º‡•Ä ‡§∏‡§´‡§≤‡§§‡§æ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§§‡•ç‡§µ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§¨‡•á‡§π‡§¶ ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§î‡§∞ ‡§ï‡§Æ‡•ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡•á‡§∂‡§®‡§≤ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§ï‡•Å‡§∂‡§≤ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£ ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§≤‡§æ‡§ó‡§§ ‡§Æ‡•á‡§Ç ‡§Ü‡§®‡•Å‡§™‡§æ‡§§‡§ø‡§ï ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§ ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§è‡§Ü‡§à ‡§ï‡§æ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§∏‡§Ç‡§≠‡§µ‡§§‡§É ‡§á‡§® ‡§Ö‡§ß‡§ø‡§ï ‡§ï‡•Å‡§∂‡§≤ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§≠‡•Å‡§§‡•ç‡§µ ‡§π‡•ã‡§ó‡§æ, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§î‡§∞ ‡§≠‡•Ä ‡§Ö‡§ß‡§ø‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§π‡§æ‡§∞‡•ç‡§°‡§µ‡•á‡§Ø‡§∞ ‡§ï‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§™‡§∞ ‡§ö‡§≤ ‡§∏‡§ï‡•á‡§Ç‡§ó‡•á, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§Ö‡§§‡•ç‡§Ø‡§æ‡§ß‡•Å‡§®‡§ø‡§ï ‡§è‡§Ü‡§à ‡§§‡§ï ‡§™‡§π‡•Å‡§Ç‡§ö ‡§ï‡§æ ‡§î‡§∞ ‡§≤‡•ã‡§ï‡§§‡§Ç‡§§‡•ç‡§∞‡•Ä‡§ï‡§∞‡§£ ‡§π‡•ã‡§ó‡§æ‡•§',
                    'sec12-career-btn': '‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ö‡§Ç‡§§‡§∞ ‡§¶‡•á‡§ñ‡•á‡§Ç',
                    'sec13-title': '13. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§è‡§Ü‡§à ‡§Ö‡§µ‡§ß‡§æ‡§∞‡§£‡§æ‡§è‡§Ç üìö',
                    'sec13-p1': '‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤ ‡§ï‡•á ‡§™‡•Ä‡§õ‡•á ‡§ï‡•á ‡§®‡§µ‡§æ‡§ö‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§∞‡§æ‡§π‡§®‡§æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§á‡§® ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡•ç‡§•‡§æ‡§™‡§§‡•ç‡§Ø ‡§Ö‡§µ‡§ß‡§æ‡§∞‡§£‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§',
                    'syllabus-oir-title': '‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡•ã‡§Ç ‡§ï‡§æ ‡§Æ‡§ø‡§∂‡•ç‡§∞‡§£ (MoE)',
                    'syllabus-oir-list': '<div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üß©</span><div class="flex-grow">‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§â‡§™-‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">‡§®‡•ã‡§ü‡•ç‡§∏</button><button class="lectures-btn">‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§®</button></div></div><div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üß≠</span><div class="flex-grow">‡§∞‡§æ‡§â‡§ü‡§∞ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">‡§®‡•ã‡§ü‡•ç‡§∏</button><button class="lectures-btn">‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§®</button></div></div>',
                    'syllabus-ppdt-title': '‡§µ‡§ø‡§∞‡§≤ ‡§¨‡§®‡§æ‡§Æ ‡§∏‡§ò‡§® ‡§Æ‡•â‡§°‡§≤',
                    'syllabus-ppdt-list': '<div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">üß±</span><div class="flex-grow">‡§∏‡§ò‡§® ‡§Æ‡•â‡§°‡§≤ (‡§ú‡•à‡§∏‡•á, ‡§≤‡§æ‡§Æ‡§æ 2)</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">‡§®‡•ã‡§ü‡•ç‡§∏</button><button class="lectures-btn">‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§®</button></div></div><div class="subject-item flex-col sm:flex-row"><div class="flex items-center w-full"><span class="icon">‚ú®</span><div class="flex-grow">‡§µ‡§ø‡§∞‡§≤ ‡§Æ‡•â‡§°‡§≤ (‡§ú‡•à‡§∏‡•á, ‡§Æ‡§ø‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡§≤)</div></div><div class="w-full sm:w-auto mt-2 sm:mt-0 flex justify-end flex-shrink-0 space-x-2"><button class="notes-btn">‡§®‡•ã‡§ü‡•ç‡§∏</button><button class="lectures-btn">‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§®</button></div></div>',
                    'footer-text': '&copy; 2025 | ‡§Ü‡§™‡§ï‡•á ‡§π‡§æ‡§•‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§´‡•ç‡§∞‡§Ç‡§ü‡§ø‡§Ø‡§∞ ‡§è‡§Ü‡§à‡•§',
                    'interviewChartData': {
                        labels: ['‡§è‡§Æ‡§è‡§Æ‡§è‡§≤‡§Ø‡•Ç', '‡§ú‡•Ä‡§è‡§∏‡§è‡§Æ8‡§ï‡•á', '‡§π‡•ç‡§Ø‡•Ç‡§Æ‡§®‡§á‡§µ‡§≤', '‡§è‡§Æ‡§¨‡•Ä‡§™‡•Ä‡§™‡•Ä'],
                        data: [70.6, 61.1, 40.2, 53.7]
                    }
                }
            };
            
            function renderPostCards(lang) {
                const container = document.getElementById('postCardsContainer');
                if (!container) return;
                container.innerHTML = '';
                const posts = serviceDetailsData[lang];
                for (const id in posts) {
                    const post = posts[id];
                    const card = document.createElement('div');
                    card.className = 'group relative p-6 bg-[#2a2a2a]/50 rounded-xl text-center border-2 border-neutral-700 hover:border-yellow-400 transition-all duration-300 cursor-pointer shadow-lg hover:shadow-2xl transform hover:-translate-y-2';
                    card.dataset.postId = id;
                    card.innerHTML = `
                        <div class="text-6xl mb-4 transition-transform duration-300 group-hover:scale-110">${post.icon}</div>
                        <h4 class="font-bold text-xl text-white">${post.name}</h4>
                        <p class="text-sm text-gray-400 mt-2">${post.cta}</p>
                        <div class="absolute top-3 right-3 text-yellow-400 opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M7 17l9.2-9.2M17 17V7H7"/></svg>
                        </div>
                    `;
                    card.addEventListener('click', () => showPostDetails(id));
                    container.appendChild(card);
                }
            }

            function showPostDetails(postId) {
                const post = serviceDetailsData[currentLang][postId];
                if (post) {
                    document.getElementById('postDetailIcon').innerText = post.icon;
                    document.getElementById('postDetailTitle').innerText = post.name;
                    document.getElementById('postDetailDescription').innerText = post.description;
                    showModal('postDetailModal');
                }
            }

            function renderCareerPath(lang) {
                const container = document.getElementById('careerPathContainer');
                container.innerHTML = '';
                const path = careerPathData[lang].path;
                path.forEach((step) => {
                    const stepElement = document.createElement('div');
                    stepElement.className = 'timeline-step';
                    stepElement.innerHTML = `
                        <div class="timeline-dot"></div>
                        <h4 class="font-semibold text-xl text-white mb-1">${step.rank}</h4>
                        <p class="text-base text-gray-300">${step.desc}</p>
                    `;
                    container.appendChild(stepElement);
                });
            }

            function initInterviewChart() {
                const ctx = document.getElementById('interviewQualitiesChart').getContext('2d');
                interviewChartInstance = new Chart(ctx, {
                    type: 'bar',
                    data: {
                        labels: translations.en.interviewChartData.labels,
                        datasets: [{
                            label: 'Benchmark Score',
                            data: translations.en.interviewChartData.data,
                            backgroundColor: [
                                'rgba(0, 98, 224, 0.7)',
                                'rgba(255, 199, 0, 0.7)',
                                'rgba(219, 68, 55, 0.7)',
                                'rgba(52, 168, 83, 0.7)'
                            ],
                            borderColor: [
                                '#0062E0',
                                '#FFC700',
                                '#DB4437',
                                '#34A853'
                            ],
                            borderWidth: 2,
                            borderRadius: 8,
                        }]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        plugins: { legend: { display: false } },
                        scales: {
                            y: { 
                                beginAtZero: true, 
                                max: 100,
                                ticks: { color: '#f0f0f0' },
                                grid: { color: 'rgba(240, 240, 240, 0.1)' }
                            },
                            x: { 
                                ticks: { color: '#f0f0f0', font: { size: 14 } },
                                grid: { color: 'rgba(240, 240, 240, 0.0)' }
                            }
                        }
                    }
                });
            }

            function translateChart() {
                if (interviewChartInstance) {
                    const data = translations[currentLang].interviewChartData;
                    interviewChartInstance.data.labels = data.labels;
                    interviewChartInstance.data.datasets[0].data = data.data;
                    interviewChartInstance.update();
                }
            }
            
            function translatePage(lang) {
                currentLang = lang;
                document.documentElement.lang = lang;
                for (const id in translations[lang]) {
                    const element = document.getElementById(id);
                    if (element) {
                        element.innerHTML = translations[lang][id];
                    }
                }
                renderPostCards(lang);
                renderCareerPath(lang);
                translateChart();
            }

            document.querySelectorAll('.lang-btn').forEach(button => {
                button.addEventListener('click', (e) => {
                    document.querySelectorAll('.lang-btn').forEach(btn => btn.classList.remove('active'));
                    e.currentTarget.classList.add('active');
                    translatePage(e.currentTarget.dataset.lang);
                });
            });

            const showModal = (modalId) => document.getElementById(modalId)?.classList.add('active');
            const closeModal = (modal) => modal?.classList.remove('active');

            document.querySelectorAll('[data-modal-target]').forEach(trigger => {
                trigger.addEventListener('click', () => showModal(trigger.dataset.modalTarget));
            });


            document.querySelectorAll('.modal-overlay').forEach(modal => {
                modal.addEventListener('click', (e) => {
                    if (e.target === modal) closeModal(modal);
                });
                modal.querySelector('.modal-close-button')?.addEventListener('click', () => closeModal(modal));
            });
            
            // Initial render
            initInterviewChart();
            translatePage('en');
        });
    </script>
</body>
</html>

